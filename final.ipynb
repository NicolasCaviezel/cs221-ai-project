{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network Intrusion Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# to remove\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import experiments\n",
    "import reporting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 16.5 s, sys: 2.98 s, total: 19.5 s\n",
      "Wall time: 6.82 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ni = experiments.NetworkIntrusionDetection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(494021, 42)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ni.df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 338 ms, sys: 56.8 ms, total: 395 ms\n",
      "Wall time: 394 ms\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>attacks</th>\n",
       "      <th>prevalence</th>\n",
       "      <th>prevalence (overall)</th>\n",
       "      <th>records</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>smurf.</th>\n",
       "      <td>280790</td>\n",
       "      <td>0.742697</td>\n",
       "      <td>0.568377</td>\n",
       "      <td>378068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neptune.</th>\n",
       "      <td>107201</td>\n",
       "      <td>0.524264</td>\n",
       "      <td>0.216997</td>\n",
       "      <td>204479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>back.</th>\n",
       "      <td>2203</td>\n",
       "      <td>0.022145</td>\n",
       "      <td>0.004459</td>\n",
       "      <td>99481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>satan.</th>\n",
       "      <td>1589</td>\n",
       "      <td>0.016072</td>\n",
       "      <td>0.003216</td>\n",
       "      <td>98867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ipsweep.</th>\n",
       "      <td>1247</td>\n",
       "      <td>0.012657</td>\n",
       "      <td>0.002524</td>\n",
       "      <td>98525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>portsweep.</th>\n",
       "      <td>1040</td>\n",
       "      <td>0.010578</td>\n",
       "      <td>0.002105</td>\n",
       "      <td>98318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>warezclient.</th>\n",
       "      <td>1020</td>\n",
       "      <td>0.010377</td>\n",
       "      <td>0.002065</td>\n",
       "      <td>98298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>teardrop.</th>\n",
       "      <td>979</td>\n",
       "      <td>0.009964</td>\n",
       "      <td>0.001982</td>\n",
       "      <td>98257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pod.</th>\n",
       "      <td>264</td>\n",
       "      <td>0.002707</td>\n",
       "      <td>0.000534</td>\n",
       "      <td>97542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nmap.</th>\n",
       "      <td>231</td>\n",
       "      <td>0.002369</td>\n",
       "      <td>0.000468</td>\n",
       "      <td>97509</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              attacks  prevalence  prevalence (overall)  records\n",
       "label                                                           \n",
       "smurf.         280790    0.742697              0.568377   378068\n",
       "neptune.       107201    0.524264              0.216997   204479\n",
       "back.            2203    0.022145              0.004459    99481\n",
       "satan.           1589    0.016072              0.003216    98867\n",
       "ipsweep.         1247    0.012657              0.002524    98525\n",
       "portsweep.       1040    0.010578              0.002105    98318\n",
       "warezclient.     1020    0.010377              0.002065    98298\n",
       "teardrop.         979    0.009964              0.001982    98257\n",
       "pod.              264    0.002707              0.000534    97542\n",
       "nmap.             231    0.002369              0.000468    97509"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "ni.report_labels()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline and Oracle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 22.7 s, sys: 6.08 s, total: 28.7 s\n",
      "Wall time: 17.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_baseline_oracle = ni.report_baseline_oracle()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>baseline_random_FN</th>\n",
       "      <th>baseline_random_FP</th>\n",
       "      <th>baseline_random_f1</th>\n",
       "      <th>baseline_random_precision</th>\n",
       "      <th>baseline_random_recall</th>\n",
       "      <th>baseline_unsupervised_FN</th>\n",
       "      <th>baseline_unsupervised_FP</th>\n",
       "      <th>baseline_unsupervised_f1</th>\n",
       "      <th>baseline_unsupervised_precision</th>\n",
       "      <th>baseline_unsupervised_recall</th>\n",
       "      <th>oracle_FN</th>\n",
       "      <th>oracle_FP</th>\n",
       "      <th>oracle_average precision</th>\n",
       "      <th>oracle_f1</th>\n",
       "      <th>oracle_precision</th>\n",
       "      <th>oracle_recall</th>\n",
       "      <th>oracle_roc auc</th>\n",
       "      <th>oracle_train time (s)</th>\n",
       "      <th>prevalence</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>smurf.</th>\n",
       "      <td>7186.5</td>\n",
       "      <td>7214.0</td>\n",
       "      <td>0.743104</td>\n",
       "      <td>0.743598</td>\n",
       "      <td>0.744061</td>\n",
       "      <td>19212</td>\n",
       "      <td>9728</td>\n",
       "      <td>0.379955</td>\n",
       "      <td>0.476849</td>\n",
       "      <td>0.315788</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.728290</td>\n",
       "      <td>0.742698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neptune.</th>\n",
       "      <td>5104.5</td>\n",
       "      <td>5080.5</td>\n",
       "      <td>0.525150</td>\n",
       "      <td>0.526556</td>\n",
       "      <td>0.523834</td>\n",
       "      <td>5485</td>\n",
       "      <td>5534</td>\n",
       "      <td>0.487226</td>\n",
       "      <td>0.486118</td>\n",
       "      <td>0.488340</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999953</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999907</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.478475</td>\n",
       "      <td>0.524266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>back.</th>\n",
       "      <td>215.5</td>\n",
       "      <td>226.0</td>\n",
       "      <td>0.020227</td>\n",
       "      <td>0.020008</td>\n",
       "      <td>0.020455</td>\n",
       "      <td>202</td>\n",
       "      <td>180</td>\n",
       "      <td>0.086124</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.081818</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.161669</td>\n",
       "      <td>0.022153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>satan.</th>\n",
       "      <td>155.0</td>\n",
       "      <td>155.5</td>\n",
       "      <td>0.026016</td>\n",
       "      <td>0.026936</td>\n",
       "      <td>0.025157</td>\n",
       "      <td>13</td>\n",
       "      <td>16</td>\n",
       "      <td>0.909657</td>\n",
       "      <td>0.901235</td>\n",
       "      <td>0.918239</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.258113</td>\n",
       "      <td>0.016070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ipsweep.</th>\n",
       "      <td>123.5</td>\n",
       "      <td>122.5</td>\n",
       "      <td>0.011177</td>\n",
       "      <td>0.010597</td>\n",
       "      <td>0.012000</td>\n",
       "      <td>116</td>\n",
       "      <td>130</td>\n",
       "      <td>0.068182</td>\n",
       "      <td>0.064748</td>\n",
       "      <td>0.072000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.142372</td>\n",
       "      <td>0.012649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>portsweep.</th>\n",
       "      <td>103.0</td>\n",
       "      <td>97.5</td>\n",
       "      <td>0.009501</td>\n",
       "      <td>0.009390</td>\n",
       "      <td>0.009615</td>\n",
       "      <td>50</td>\n",
       "      <td>44</td>\n",
       "      <td>0.534653</td>\n",
       "      <td>0.551020</td>\n",
       "      <td>0.519231</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.990486</td>\n",
       "      <td>0.995169</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.990385</td>\n",
       "      <td>0.995188</td>\n",
       "      <td>0.160033</td>\n",
       "      <td>0.010578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>warezclient.</th>\n",
       "      <td>101.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>0.009179</td>\n",
       "      <td>0.008637</td>\n",
       "      <td>0.009804</td>\n",
       "      <td>101</td>\n",
       "      <td>84</td>\n",
       "      <td>0.010695</td>\n",
       "      <td>0.011765</td>\n",
       "      <td>0.009804</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999534</td>\n",
       "      <td>0.990099</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.980392</td>\n",
       "      <td>0.999997</td>\n",
       "      <td>0.244905</td>\n",
       "      <td>0.010377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>teardrop.</th>\n",
       "      <td>97.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>0.009975</td>\n",
       "      <td>0.009756</td>\n",
       "      <td>0.010204</td>\n",
       "      <td>68</td>\n",
       "      <td>73</td>\n",
       "      <td>0.298507</td>\n",
       "      <td>0.291262</td>\n",
       "      <td>0.306122</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.141988</td>\n",
       "      <td>0.009961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pod.</th>\n",
       "      <td>26.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>26</td>\n",
       "      <td>39</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.980392</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.140743</td>\n",
       "      <td>0.002717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nmap.</th>\n",
       "      <td>23.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>0.510638</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.521739</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.163670</td>\n",
       "      <td>0.002372</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              baseline_random_FN  baseline_random_FP  baseline_random_f1  \\\n",
       "label                                                                      \n",
       "smurf.                    7186.5              7214.0            0.743104   \n",
       "neptune.                  5104.5              5080.5            0.525150   \n",
       "back.                      215.5               226.0            0.020227   \n",
       "satan.                     155.0               155.5            0.026016   \n",
       "ipsweep.                   123.5               122.5            0.011177   \n",
       "portsweep.                 103.0                97.5            0.009501   \n",
       "warezclient.               101.0               103.0            0.009179   \n",
       "teardrop.                   97.0                97.0            0.009975   \n",
       "pod.                        26.0                26.0            0.000000   \n",
       "nmap.                       23.0                23.0            0.000000   \n",
       "\n",
       "              baseline_random_precision  baseline_random_recall  \\\n",
       "label                                                             \n",
       "smurf.                         0.743598                0.744061   \n",
       "neptune.                       0.526556                0.523834   \n",
       "back.                          0.020008                0.020455   \n",
       "satan.                         0.026936                0.025157   \n",
       "ipsweep.                       0.010597                0.012000   \n",
       "portsweep.                     0.009390                0.009615   \n",
       "warezclient.                   0.008637                0.009804   \n",
       "teardrop.                      0.009756                0.010204   \n",
       "pod.                           0.000000                0.000000   \n",
       "nmap.                          0.000000                0.000000   \n",
       "\n",
       "              baseline_unsupervised_FN  baseline_unsupervised_FP  \\\n",
       "label                                                              \n",
       "smurf.                           19212                      9728   \n",
       "neptune.                          5485                      5534   \n",
       "back.                              202                       180   \n",
       "satan.                              13                        16   \n",
       "ipsweep.                           116                       130   \n",
       "portsweep.                          50                        44   \n",
       "warezclient.                       101                        84   \n",
       "teardrop.                           68                        73   \n",
       "pod.                                26                        39   \n",
       "nmap.                               11                        12   \n",
       "\n",
       "              baseline_unsupervised_f1  baseline_unsupervised_precision  \\\n",
       "label                                                                     \n",
       "smurf.                        0.379955                         0.476849   \n",
       "neptune.                      0.487226                         0.486118   \n",
       "back.                         0.086124                         0.090909   \n",
       "satan.                        0.909657                         0.901235   \n",
       "ipsweep.                      0.068182                         0.064748   \n",
       "portsweep.                    0.534653                         0.551020   \n",
       "warezclient.                  0.010695                         0.011765   \n",
       "teardrop.                     0.298507                         0.291262   \n",
       "pod.                          0.000000                         0.000000   \n",
       "nmap.                         0.510638                         0.500000   \n",
       "\n",
       "              baseline_unsupervised_recall  oracle_FN  oracle_FP  \\\n",
       "label                                                              \n",
       "smurf.                            0.315788          0          0   \n",
       "neptune.                          0.488340          1          0   \n",
       "back.                             0.081818          0          0   \n",
       "satan.                            0.918239          0          0   \n",
       "ipsweep.                          0.072000          0          0   \n",
       "portsweep.                        0.519231          1          0   \n",
       "warezclient.                      0.009804          2          0   \n",
       "teardrop.                         0.306122          0          0   \n",
       "pod.                              0.000000          1          0   \n",
       "nmap.                             0.521739          0          0   \n",
       "\n",
       "              oracle_average precision  oracle_f1  oracle_precision  \\\n",
       "label                                                                 \n",
       "smurf.                        1.000000   1.000000               1.0   \n",
       "neptune.                      1.000000   0.999953               1.0   \n",
       "back.                         1.000000   1.000000               1.0   \n",
       "satan.                        1.000000   1.000000               1.0   \n",
       "ipsweep.                      1.000000   1.000000               1.0   \n",
       "portsweep.                    0.990486   0.995169               1.0   \n",
       "warezclient.                  0.999534   0.990099               1.0   \n",
       "teardrop.                     1.000000   1.000000               1.0   \n",
       "pod.                          1.000000   0.980392               1.0   \n",
       "nmap.                         1.000000   1.000000               1.0   \n",
       "\n",
       "              oracle_recall  oracle_roc auc  oracle_train time (s)  prevalence  \n",
       "label                                                                           \n",
       "smurf.             1.000000        1.000000               0.728290    0.742698  \n",
       "neptune.           0.999907        1.000000               0.478475    0.524266  \n",
       "back.              1.000000        1.000000               0.161669    0.022153  \n",
       "satan.             1.000000        1.000000               0.258113    0.016070  \n",
       "ipsweep.           1.000000        1.000000               0.142372    0.012649  \n",
       "portsweep.         0.990385        0.995188               0.160033    0.010578  \n",
       "warezclient.       0.980392        0.999997               0.244905    0.010377  \n",
       "teardrop.          1.000000        1.000000               0.141988    0.009961  \n",
       "pod.               0.961538        1.000000               0.140743    0.002717  \n",
       "nmap.              1.000000        1.000000               0.163670    0.002372  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_baseline_oracle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "baseline_random_FN                 1313.50\n",
       "baseline_random_FP                 1314.50\n",
       "baseline_random_f1                    0.14\n",
       "baseline_random_precision             0.14\n",
       "baseline_random_recall                0.14\n",
       "baseline_unsupervised_FN           2528.40\n",
       "baseline_unsupervised_FP           1584.00\n",
       "baseline_unsupervised_f1              0.33\n",
       "baseline_unsupervised_precision       0.34\n",
       "baseline_unsupervised_recall          0.32\n",
       "oracle_FN                             0.50\n",
       "oracle_FP                             0.00\n",
       "oracle_average precision              1.00\n",
       "oracle_f1                             1.00\n",
       "oracle_precision                      1.00\n",
       "oracle_recall                         0.99\n",
       "oracle_roc auc                        1.00\n",
       "oracle_train time (s)                 0.26\n",
       "prevalence                            0.14\n",
       "dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_baseline_oracle.mean().round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "baseline_random_FN                 2594.14\n",
       "baseline_random_FP                 2596.90\n",
       "baseline_random_f1                    0.27\n",
       "baseline_random_precision             0.27\n",
       "baseline_random_recall                0.27\n",
       "baseline_unsupervised_FN           6104.01\n",
       "baseline_unsupervised_FP           3337.23\n",
       "baseline_unsupervised_f1              0.29\n",
       "baseline_unsupervised_precision       0.30\n",
       "baseline_unsupervised_recall          0.30\n",
       "oracle_FN                             0.71\n",
       "oracle_FP                             0.00\n",
       "oracle_average precision              0.00\n",
       "oracle_f1                             0.01\n",
       "oracle_precision                      0.00\n",
       "oracle_recall                         0.01\n",
       "oracle_roc auc                        0.00\n",
       "oracle_train time (s)                 0.19\n",
       "prevalence                            0.27\n",
       "dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_baseline_oracle.std().round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Active Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>initial_FN</th>\n",
       "      <th>initial_FP</th>\n",
       "      <th>initial_average precision</th>\n",
       "      <th>initial_f1</th>\n",
       "      <th>initial_precision</th>\n",
       "      <th>initial_recall</th>\n",
       "      <th>initial_roc auc</th>\n",
       "      <th>label</th>\n",
       "      <th>learner</th>\n",
       "      <th>query time (s)</th>\n",
       "      <th>sample_100_FN</th>\n",
       "      <th>sample_100_FP</th>\n",
       "      <th>sample_100_average precision</th>\n",
       "      <th>sample_100_f1</th>\n",
       "      <th>sample_100_precision</th>\n",
       "      <th>sample_100_recall</th>\n",
       "      <th>sample_100_roc auc</th>\n",
       "      <th>sample_10_FN</th>\n",
       "      <th>sample_10_FP</th>\n",
       "      <th>sample_10_average precision</th>\n",
       "      <th>sample_10_f1</th>\n",
       "      <th>sample_10_precision</th>\n",
       "      <th>sample_10_recall</th>\n",
       "      <th>sample_10_roc auc</th>\n",
       "      <th>sample_1_FN</th>\n",
       "      <th>sample_1_FP</th>\n",
       "      <th>sample_1_average precision</th>\n",
       "      <th>sample_1_f1</th>\n",
       "      <th>sample_1_precision</th>\n",
       "      <th>sample_1_recall</th>\n",
       "      <th>sample_1_roc auc</th>\n",
       "      <th>sample_25_FN</th>\n",
       "      <th>sample_25_FP</th>\n",
       "      <th>sample_25_average precision</th>\n",
       "      <th>sample_25_f1</th>\n",
       "      <th>sample_25_precision</th>\n",
       "      <th>sample_25_recall</th>\n",
       "      <th>sample_25_roc auc</th>\n",
       "      <th>sample_50_FN</th>\n",
       "      <th>sample_50_FP</th>\n",
       "      <th>sample_50_average precision</th>\n",
       "      <th>sample_50_f1</th>\n",
       "      <th>sample_50_precision</th>\n",
       "      <th>sample_50_recall</th>\n",
       "      <th>sample_50_roc auc</th>\n",
       "      <th>sampling strategy</th>\n",
       "      <th>train time (s)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999822</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999644</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>smurf.</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.113536</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999786</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999573</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999822</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999644</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999822</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999644</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999786</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999573</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999786</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999573</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>random_sampling</td>\n",
       "      <td>0.105282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999822</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999644</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>smurf.</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.111460</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999893</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999786</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>entropy_sampling</td>\n",
       "      <td>0.109376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>57</td>\n",
       "      <td>0.999997</td>\n",
       "      <td>0.998826</td>\n",
       "      <td>0.997973</td>\n",
       "      <td>0.999679</td>\n",
       "      <td>0.999991</td>\n",
       "      <td>smurf.</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.002383</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>0.999799</td>\n",
       "      <td>0.999733</td>\n",
       "      <td>0.999786</td>\n",
       "      <td>0.999679</td>\n",
       "      <td>0.999891</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.999751</td>\n",
       "      <td>0.999822</td>\n",
       "      <td>0.999679</td>\n",
       "      <td>0.999995</td>\n",
       "      <td>9</td>\n",
       "      <td>67</td>\n",
       "      <td>0.999922</td>\n",
       "      <td>0.998648</td>\n",
       "      <td>0.997619</td>\n",
       "      <td>0.999679</td>\n",
       "      <td>0.999886</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>0.999798</td>\n",
       "      <td>0.999733</td>\n",
       "      <td>0.999786</td>\n",
       "      <td>0.999679</td>\n",
       "      <td>0.999890</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>0.999805</td>\n",
       "      <td>0.999768</td>\n",
       "      <td>0.999858</td>\n",
       "      <td>0.999679</td>\n",
       "      <td>0.999890</td>\n",
       "      <td>random_sampling</td>\n",
       "      <td>0.024312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>57</td>\n",
       "      <td>0.999997</td>\n",
       "      <td>0.998826</td>\n",
       "      <td>0.997973</td>\n",
       "      <td>0.999679</td>\n",
       "      <td>0.999991</td>\n",
       "      <td>smurf.</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.002559</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999858</td>\n",
       "      <td>0.999751</td>\n",
       "      <td>0.999964</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>0.999818</td>\n",
       "      <td>0.999786</td>\n",
       "      <td>0.999893</td>\n",
       "      <td>0.999679</td>\n",
       "      <td>0.999888</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.999820</td>\n",
       "      <td>0.999893</td>\n",
       "      <td>0.999822</td>\n",
       "      <td>0.999964</td>\n",
       "      <td>0.999793</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999964</td>\n",
       "      <td>0.999929</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>entropy_sampling</td>\n",
       "      <td>0.026511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999813</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999627</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>neptune.</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.112695</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999860</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999720</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999813</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999627</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999813</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999627</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999860</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999720</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999860</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999720</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>random_sampling</td>\n",
       "      <td>0.109523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999813</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999627</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>neptune.</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.112593</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999953</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999907</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999953</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999907</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999813</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999627</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999953</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999907</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999953</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999907</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>entropy_sampling</td>\n",
       "      <td>0.108728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>0.999993</td>\n",
       "      <td>0.999580</td>\n",
       "      <td>0.999720</td>\n",
       "      <td>0.999440</td>\n",
       "      <td>0.999992</td>\n",
       "      <td>neptune.</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.001880</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>0.999994</td>\n",
       "      <td>0.999627</td>\n",
       "      <td>0.999813</td>\n",
       "      <td>0.999440</td>\n",
       "      <td>0.999993</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>0.999994</td>\n",
       "      <td>0.999627</td>\n",
       "      <td>0.999813</td>\n",
       "      <td>0.999440</td>\n",
       "      <td>0.999993</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>0.999994</td>\n",
       "      <td>0.999627</td>\n",
       "      <td>0.999813</td>\n",
       "      <td>0.999440</td>\n",
       "      <td>0.999993</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>0.999993</td>\n",
       "      <td>0.999627</td>\n",
       "      <td>0.999813</td>\n",
       "      <td>0.999440</td>\n",
       "      <td>0.999992</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999996</td>\n",
       "      <td>0.999720</td>\n",
       "      <td>0.999907</td>\n",
       "      <td>0.999534</td>\n",
       "      <td>0.999996</td>\n",
       "      <td>random_sampling</td>\n",
       "      <td>0.024976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>0.999993</td>\n",
       "      <td>0.999580</td>\n",
       "      <td>0.999720</td>\n",
       "      <td>0.999440</td>\n",
       "      <td>0.999992</td>\n",
       "      <td>neptune.</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.002293</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999953</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999907</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>0.999870</td>\n",
       "      <td>0.999347</td>\n",
       "      <td>0.999254</td>\n",
       "      <td>0.999440</td>\n",
       "      <td>0.999922</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999996</td>\n",
       "      <td>0.999720</td>\n",
       "      <td>0.999907</td>\n",
       "      <td>0.999534</td>\n",
       "      <td>0.999995</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999907</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999813</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999953</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999907</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>entropy_sampling</td>\n",
       "      <td>0.026525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.995434</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.990909</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>back.</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.109122</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.995434</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.990909</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.993135</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.986364</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.995434</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.990909</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>random_sampling</td>\n",
       "      <td>0.105342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.995434</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.990909</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>back.</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.104424</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.990826</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.981818</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.997722</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.995455</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>entropy_sampling</td>\n",
       "      <td>0.110879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>24</td>\n",
       "      <td>0.809557</td>\n",
       "      <td>0.939130</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.981818</td>\n",
       "      <td>0.997958</td>\n",
       "      <td>back.</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.000712</td>\n",
       "      <td>44</td>\n",
       "      <td>13</td>\n",
       "      <td>0.841507</td>\n",
       "      <td>0.860636</td>\n",
       "      <td>0.931217</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.993959</td>\n",
       "      <td>4</td>\n",
       "      <td>25</td>\n",
       "      <td>0.804823</td>\n",
       "      <td>0.937093</td>\n",
       "      <td>0.896266</td>\n",
       "      <td>0.981818</td>\n",
       "      <td>0.997880</td>\n",
       "      <td>5</td>\n",
       "      <td>22</td>\n",
       "      <td>0.831127</td>\n",
       "      <td>0.940919</td>\n",
       "      <td>0.907173</td>\n",
       "      <td>0.977273</td>\n",
       "      <td>0.998045</td>\n",
       "      <td>5</td>\n",
       "      <td>19</td>\n",
       "      <td>0.830619</td>\n",
       "      <td>0.947137</td>\n",
       "      <td>0.918803</td>\n",
       "      <td>0.977273</td>\n",
       "      <td>0.997239</td>\n",
       "      <td>6</td>\n",
       "      <td>20</td>\n",
       "      <td>0.828801</td>\n",
       "      <td>0.942731</td>\n",
       "      <td>0.914530</td>\n",
       "      <td>0.972727</td>\n",
       "      <td>0.996983</td>\n",
       "      <td>random_sampling</td>\n",
       "      <td>0.034752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>24</td>\n",
       "      <td>0.809557</td>\n",
       "      <td>0.939130</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.981818</td>\n",
       "      <td>0.997958</td>\n",
       "      <td>back.</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.000772</td>\n",
       "      <td>5</td>\n",
       "      <td>19</td>\n",
       "      <td>0.845314</td>\n",
       "      <td>0.947137</td>\n",
       "      <td>0.918803</td>\n",
       "      <td>0.977273</td>\n",
       "      <td>0.997945</td>\n",
       "      <td>5</td>\n",
       "      <td>24</td>\n",
       "      <td>0.821783</td>\n",
       "      <td>0.936819</td>\n",
       "      <td>0.899582</td>\n",
       "      <td>0.977273</td>\n",
       "      <td>0.998050</td>\n",
       "      <td>4</td>\n",
       "      <td>23</td>\n",
       "      <td>0.817392</td>\n",
       "      <td>0.941176</td>\n",
       "      <td>0.903766</td>\n",
       "      <td>0.981818</td>\n",
       "      <td>0.998180</td>\n",
       "      <td>4</td>\n",
       "      <td>19</td>\n",
       "      <td>0.842252</td>\n",
       "      <td>0.949451</td>\n",
       "      <td>0.919149</td>\n",
       "      <td>0.981818</td>\n",
       "      <td>0.998661</td>\n",
       "      <td>5</td>\n",
       "      <td>19</td>\n",
       "      <td>0.835839</td>\n",
       "      <td>0.947137</td>\n",
       "      <td>0.918803</td>\n",
       "      <td>0.977273</td>\n",
       "      <td>0.998291</td>\n",
       "      <td>entropy_sampling</td>\n",
       "      <td>0.033389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0.990126</td>\n",
       "      <td>0.947020</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.899371</td>\n",
       "      <td>0.999877</td>\n",
       "      <td>satan.</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.105923</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>0.951424</td>\n",
       "      <td>0.943522</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.893082</td>\n",
       "      <td>0.977850</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>0.990345</td>\n",
       "      <td>0.943522</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.893082</td>\n",
       "      <td>0.999888</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0.990126</td>\n",
       "      <td>0.947020</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.899371</td>\n",
       "      <td>0.999877</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>0.951424</td>\n",
       "      <td>0.943522</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.893082</td>\n",
       "      <td>0.977850</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>0.951424</td>\n",
       "      <td>0.943522</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.893082</td>\n",
       "      <td>0.977850</td>\n",
       "      <td>random_sampling</td>\n",
       "      <td>0.110261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0.990126</td>\n",
       "      <td>0.947020</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.899371</td>\n",
       "      <td>0.999877</td>\n",
       "      <td>satan.</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.105800</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.997102</td>\n",
       "      <td>0.984026</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.968553</td>\n",
       "      <td>0.999961</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0.987498</td>\n",
       "      <td>0.947020</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.899371</td>\n",
       "      <td>0.999831</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>entropy_sampling</td>\n",
       "      <td>0.110374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>0.997285</td>\n",
       "      <td>0.943522</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.893082</td>\n",
       "      <td>0.999946</td>\n",
       "      <td>satan.</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.001129</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>0.997233</td>\n",
       "      <td>0.943522</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.893082</td>\n",
       "      <td>0.999944</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>0.997285</td>\n",
       "      <td>0.943522</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.893082</td>\n",
       "      <td>0.999946</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>0.997285</td>\n",
       "      <td>0.943522</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.893082</td>\n",
       "      <td>0.999946</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>0.997257</td>\n",
       "      <td>0.943522</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.893082</td>\n",
       "      <td>0.999945</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>0.997233</td>\n",
       "      <td>0.943522</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.893082</td>\n",
       "      <td>0.999944</td>\n",
       "      <td>random_sampling</td>\n",
       "      <td>0.032182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>0.997285</td>\n",
       "      <td>0.943522</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.893082</td>\n",
       "      <td>0.999946</td>\n",
       "      <td>satan.</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.000904</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999699</td>\n",
       "      <td>0.993711</td>\n",
       "      <td>0.993711</td>\n",
       "      <td>0.993711</td>\n",
       "      <td>0.999995</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>0.991531</td>\n",
       "      <td>0.966154</td>\n",
       "      <td>0.945783</td>\n",
       "      <td>0.987421</td>\n",
       "      <td>0.999918</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0.994933</td>\n",
       "      <td>0.950495</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.905660</td>\n",
       "      <td>0.999885</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.994705</td>\n",
       "      <td>0.993711</td>\n",
       "      <td>0.993711</td>\n",
       "      <td>0.993711</td>\n",
       "      <td>0.999452</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.994886</td>\n",
       "      <td>0.990596</td>\n",
       "      <td>0.987500</td>\n",
       "      <td>0.993711</td>\n",
       "      <td>0.999553</td>\n",
       "      <td>entropy_sampling</td>\n",
       "      <td>0.027748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.997280</td>\n",
       "      <td>0.983740</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.968000</td>\n",
       "      <td>0.999960</td>\n",
       "      <td>ipsweep.</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.102991</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.998426</td>\n",
       "      <td>0.983740</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.968000</td>\n",
       "      <td>0.999988</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.997280</td>\n",
       "      <td>0.983740</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.968000</td>\n",
       "      <td>0.999960</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.997280</td>\n",
       "      <td>0.983740</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.968000</td>\n",
       "      <td>0.999960</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0.995468</td>\n",
       "      <td>0.971888</td>\n",
       "      <td>0.975806</td>\n",
       "      <td>0.968000</td>\n",
       "      <td>0.999943</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999250</td>\n",
       "      <td>0.983740</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.968000</td>\n",
       "      <td>0.999995</td>\n",
       "      <td>random_sampling</td>\n",
       "      <td>0.109571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.997280</td>\n",
       "      <td>0.983740</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.968000</td>\n",
       "      <td>0.999960</td>\n",
       "      <td>ipsweep.</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.103194</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.995984</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.992000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.997330</td>\n",
       "      <td>0.983740</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.968000</td>\n",
       "      <td>0.999961</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999634</td>\n",
       "      <td>0.995984</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.992000</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.995984</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.992000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>entropy_sampling</td>\n",
       "      <td>0.107601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>0.931825</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.921260</td>\n",
       "      <td>0.936000</td>\n",
       "      <td>0.998863</td>\n",
       "      <td>ipsweep.</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.000936</td>\n",
       "      <td>8</td>\n",
       "      <td>13</td>\n",
       "      <td>0.871723</td>\n",
       "      <td>0.917647</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.936000</td>\n",
       "      <td>0.998775</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "      <td>0.874442</td>\n",
       "      <td>0.921260</td>\n",
       "      <td>0.906977</td>\n",
       "      <td>0.936000</td>\n",
       "      <td>0.998763</td>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "      <td>0.871534</td>\n",
       "      <td>0.924901</td>\n",
       "      <td>0.914062</td>\n",
       "      <td>0.936000</td>\n",
       "      <td>0.998797</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "      <td>0.869079</td>\n",
       "      <td>0.921260</td>\n",
       "      <td>0.906977</td>\n",
       "      <td>0.936000</td>\n",
       "      <td>0.998792</td>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "      <td>0.876126</td>\n",
       "      <td>0.924901</td>\n",
       "      <td>0.914062</td>\n",
       "      <td>0.936000</td>\n",
       "      <td>0.998799</td>\n",
       "      <td>random_sampling</td>\n",
       "      <td>0.028906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>0.931825</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.921260</td>\n",
       "      <td>0.936000</td>\n",
       "      <td>0.998863</td>\n",
       "      <td>ipsweep.</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.000780</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.985864</td>\n",
       "      <td>0.987854</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.976000</td>\n",
       "      <td>0.998261</td>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "      <td>0.875916</td>\n",
       "      <td>0.924901</td>\n",
       "      <td>0.914062</td>\n",
       "      <td>0.936000</td>\n",
       "      <td>0.998791</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.993155</td>\n",
       "      <td>0.991935</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.984000</td>\n",
       "      <td>0.999391</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.996878</td>\n",
       "      <td>0.995984</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.992000</td>\n",
       "      <td>0.999934</td>\n",
       "      <td>entropy_sampling</td>\n",
       "      <td>0.032190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.990394</td>\n",
       "      <td>0.990291</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.980769</td>\n",
       "      <td>0.995170</td>\n",
       "      <td>portsweep.</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.108250</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0.989747</td>\n",
       "      <td>0.954774</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.913462</td>\n",
       "      <td>0.995164</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.990394</td>\n",
       "      <td>0.990291</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.980769</td>\n",
       "      <td>0.995170</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.990394</td>\n",
       "      <td>0.990291</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.980769</td>\n",
       "      <td>0.995170</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0.989747</td>\n",
       "      <td>0.954774</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.913462</td>\n",
       "      <td>0.995164</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0.989747</td>\n",
       "      <td>0.954774</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.913462</td>\n",
       "      <td>0.995164</td>\n",
       "      <td>random_sampling</td>\n",
       "      <td>0.107740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.990394</td>\n",
       "      <td>0.990291</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.980769</td>\n",
       "      <td>0.995170</td>\n",
       "      <td>portsweep.</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.105511</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.990486</td>\n",
       "      <td>0.995169</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.990385</td>\n",
       "      <td>0.995178</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.990486</td>\n",
       "      <td>0.990291</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.980769</td>\n",
       "      <td>0.995172</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.990214</td>\n",
       "      <td>0.985366</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.971154</td>\n",
       "      <td>0.995167</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.990486</td>\n",
       "      <td>0.995169</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.990385</td>\n",
       "      <td>0.995178</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.990486</td>\n",
       "      <td>0.995169</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.990385</td>\n",
       "      <td>0.995173</td>\n",
       "      <td>entropy_sampling</td>\n",
       "      <td>0.110793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>104</td>\n",
       "      <td>0</td>\n",
       "      <td>0.070932</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.896795</td>\n",
       "      <td>portsweep.</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.000972</td>\n",
       "      <td>104</td>\n",
       "      <td>0</td>\n",
       "      <td>0.421563</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.954305</td>\n",
       "      <td>97</td>\n",
       "      <td>0</td>\n",
       "      <td>0.276677</td>\n",
       "      <td>0.126126</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.067308</td>\n",
       "      <td>0.981104</td>\n",
       "      <td>104</td>\n",
       "      <td>0</td>\n",
       "      <td>0.065582</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.880780</td>\n",
       "      <td>93</td>\n",
       "      <td>3</td>\n",
       "      <td>0.510700</td>\n",
       "      <td>0.186441</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.105769</td>\n",
       "      <td>0.946361</td>\n",
       "      <td>104</td>\n",
       "      <td>0</td>\n",
       "      <td>0.380633</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.953418</td>\n",
       "      <td>random_sampling</td>\n",
       "      <td>0.024480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>104</td>\n",
       "      <td>0</td>\n",
       "      <td>0.070932</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.896795</td>\n",
       "      <td>portsweep.</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.001048</td>\n",
       "      <td>14</td>\n",
       "      <td>101</td>\n",
       "      <td>0.900571</td>\n",
       "      <td>0.610169</td>\n",
       "      <td>0.471204</td>\n",
       "      <td>0.865385</td>\n",
       "      <td>0.997089</td>\n",
       "      <td>93</td>\n",
       "      <td>1</td>\n",
       "      <td>0.480969</td>\n",
       "      <td>0.189655</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.105769</td>\n",
       "      <td>0.943884</td>\n",
       "      <td>97</td>\n",
       "      <td>0</td>\n",
       "      <td>0.528734</td>\n",
       "      <td>0.126126</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.067308</td>\n",
       "      <td>0.993985</td>\n",
       "      <td>93</td>\n",
       "      <td>1</td>\n",
       "      <td>0.464382</td>\n",
       "      <td>0.189655</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.105769</td>\n",
       "      <td>0.963702</td>\n",
       "      <td>104</td>\n",
       "      <td>0</td>\n",
       "      <td>0.113923</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.905436</td>\n",
       "      <td>entropy_sampling</td>\n",
       "      <td>0.024552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>21</td>\n",
       "      <td>2</td>\n",
       "      <td>0.941510</td>\n",
       "      <td>0.875676</td>\n",
       "      <td>0.975904</td>\n",
       "      <td>0.794118</td>\n",
       "      <td>0.984869</td>\n",
       "      <td>warezclient.</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.106202</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>0.939357</td>\n",
       "      <td>0.905263</td>\n",
       "      <td>0.977273</td>\n",
       "      <td>0.843137</td>\n",
       "      <td>0.979797</td>\n",
       "      <td>21</td>\n",
       "      <td>2</td>\n",
       "      <td>0.950928</td>\n",
       "      <td>0.875676</td>\n",
       "      <td>0.975904</td>\n",
       "      <td>0.794118</td>\n",
       "      <td>0.994649</td>\n",
       "      <td>21</td>\n",
       "      <td>2</td>\n",
       "      <td>0.950928</td>\n",
       "      <td>0.875676</td>\n",
       "      <td>0.975904</td>\n",
       "      <td>0.794118</td>\n",
       "      <td>0.994649</td>\n",
       "      <td>29</td>\n",
       "      <td>2</td>\n",
       "      <td>0.918023</td>\n",
       "      <td>0.824859</td>\n",
       "      <td>0.973333</td>\n",
       "      <td>0.715686</td>\n",
       "      <td>0.974589</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>0.916512</td>\n",
       "      <td>0.849162</td>\n",
       "      <td>0.987013</td>\n",
       "      <td>0.745098</td>\n",
       "      <td>0.974607</td>\n",
       "      <td>random_sampling</td>\n",
       "      <td>0.109358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21</td>\n",
       "      <td>2</td>\n",
       "      <td>0.941510</td>\n",
       "      <td>0.875676</td>\n",
       "      <td>0.975904</td>\n",
       "      <td>0.794118</td>\n",
       "      <td>0.984869</td>\n",
       "      <td>warezclient.</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.105443</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.977429</td>\n",
       "      <td>0.974874</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.950980</td>\n",
       "      <td>0.999635</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0.964411</td>\n",
       "      <td>0.959596</td>\n",
       "      <td>0.989583</td>\n",
       "      <td>0.931373</td>\n",
       "      <td>0.994499</td>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "      <td>0.950295</td>\n",
       "      <td>0.899471</td>\n",
       "      <td>0.977011</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.994624</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>0.964004</td>\n",
       "      <td>0.954774</td>\n",
       "      <td>0.979381</td>\n",
       "      <td>0.931373</td>\n",
       "      <td>0.999211</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.971608</td>\n",
       "      <td>0.970000</td>\n",
       "      <td>0.989796</td>\n",
       "      <td>0.950980</td>\n",
       "      <td>0.999500</td>\n",
       "      <td>entropy_sampling</td>\n",
       "      <td>0.109547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20</td>\n",
       "      <td>22</td>\n",
       "      <td>0.819296</td>\n",
       "      <td>0.796117</td>\n",
       "      <td>0.788462</td>\n",
       "      <td>0.803922</td>\n",
       "      <td>0.920803</td>\n",
       "      <td>warezclient.</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.000847</td>\n",
       "      <td>17</td>\n",
       "      <td>26</td>\n",
       "      <td>0.791339</td>\n",
       "      <td>0.798122</td>\n",
       "      <td>0.765766</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.920601</td>\n",
       "      <td>18</td>\n",
       "      <td>13</td>\n",
       "      <td>0.817287</td>\n",
       "      <td>0.844221</td>\n",
       "      <td>0.865979</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>0.920969</td>\n",
       "      <td>17</td>\n",
       "      <td>9</td>\n",
       "      <td>0.788670</td>\n",
       "      <td>0.867347</td>\n",
       "      <td>0.904255</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.922778</td>\n",
       "      <td>16</td>\n",
       "      <td>10</td>\n",
       "      <td>0.821141</td>\n",
       "      <td>0.868687</td>\n",
       "      <td>0.895833</td>\n",
       "      <td>0.843137</td>\n",
       "      <td>0.923408</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>0.773538</td>\n",
       "      <td>0.843137</td>\n",
       "      <td>0.843137</td>\n",
       "      <td>0.843137</td>\n",
       "      <td>0.922300</td>\n",
       "      <td>random_sampling</td>\n",
       "      <td>0.033755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20</td>\n",
       "      <td>22</td>\n",
       "      <td>0.819296</td>\n",
       "      <td>0.796117</td>\n",
       "      <td>0.788462</td>\n",
       "      <td>0.803922</td>\n",
       "      <td>0.920803</td>\n",
       "      <td>warezclient.</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.000743</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>0.869828</td>\n",
       "      <td>0.910995</td>\n",
       "      <td>0.977528</td>\n",
       "      <td>0.852941</td>\n",
       "      <td>0.947082</td>\n",
       "      <td>15</td>\n",
       "      <td>7</td>\n",
       "      <td>0.857007</td>\n",
       "      <td>0.887755</td>\n",
       "      <td>0.925532</td>\n",
       "      <td>0.852941</td>\n",
       "      <td>0.950134</td>\n",
       "      <td>16</td>\n",
       "      <td>11</td>\n",
       "      <td>0.821069</td>\n",
       "      <td>0.864322</td>\n",
       "      <td>0.886598</td>\n",
       "      <td>0.843137</td>\n",
       "      <td>0.923721</td>\n",
       "      <td>15</td>\n",
       "      <td>7</td>\n",
       "      <td>0.874303</td>\n",
       "      <td>0.887755</td>\n",
       "      <td>0.925532</td>\n",
       "      <td>0.852941</td>\n",
       "      <td>0.926187</td>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>0.868548</td>\n",
       "      <td>0.906250</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.852941</td>\n",
       "      <td>0.930463</td>\n",
       "      <td>entropy_sampling</td>\n",
       "      <td>0.039316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.962963</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>teardrop.</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.105159</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.998728</td>\n",
       "      <td>0.974093</td>\n",
       "      <td>0.989474</td>\n",
       "      <td>0.959184</td>\n",
       "      <td>0.999992</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.962963</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.962963</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999691</td>\n",
       "      <td>0.940541</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.887755</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999691</td>\n",
       "      <td>0.984456</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.969388</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>random_sampling</td>\n",
       "      <td>0.110035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.962963</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>teardrop.</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.106465</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.979167</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.959184</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.984456</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.969388</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>entropy_sampling</td>\n",
       "      <td>0.110045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>0.971430</td>\n",
       "      <td>0.908108</td>\n",
       "      <td>0.965517</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.999575</td>\n",
       "      <td>teardrop.</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.000979</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>0.973046</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.955056</td>\n",
       "      <td>0.867347</td>\n",
       "      <td>0.999634</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>0.977824</td>\n",
       "      <td>0.919786</td>\n",
       "      <td>0.966292</td>\n",
       "      <td>0.877551</td>\n",
       "      <td>0.999716</td>\n",
       "      <td>14</td>\n",
       "      <td>4</td>\n",
       "      <td>0.963902</td>\n",
       "      <td>0.903226</td>\n",
       "      <td>0.954545</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.999464</td>\n",
       "      <td>16</td>\n",
       "      <td>6</td>\n",
       "      <td>0.953266</td>\n",
       "      <td>0.881720</td>\n",
       "      <td>0.931818</td>\n",
       "      <td>0.836735</td>\n",
       "      <td>0.999318</td>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "      <td>0.945192</td>\n",
       "      <td>0.900524</td>\n",
       "      <td>0.924731</td>\n",
       "      <td>0.877551</td>\n",
       "      <td>0.999419</td>\n",
       "      <td>random_sampling</td>\n",
       "      <td>0.045063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>0.971430</td>\n",
       "      <td>0.908108</td>\n",
       "      <td>0.965517</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.999575</td>\n",
       "      <td>teardrop.</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.000985</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.989691</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.979592</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>0.979303</td>\n",
       "      <td>0.931217</td>\n",
       "      <td>0.967033</td>\n",
       "      <td>0.897959</td>\n",
       "      <td>0.999687</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>entropy_sampling</td>\n",
       "      <td>0.030475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0.961641</td>\n",
       "      <td>0.844444</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.730769</td>\n",
       "      <td>0.980692</td>\n",
       "      <td>pod.</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.104013</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0.961641</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.980755</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0.961641</td>\n",
       "      <td>0.844444</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.730769</td>\n",
       "      <td>0.980692</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0.961641</td>\n",
       "      <td>0.844444</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.730769</td>\n",
       "      <td>0.980692</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0.961641</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.980755</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0.961641</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.980755</td>\n",
       "      <td>random_sampling</td>\n",
       "      <td>0.110185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0.961641</td>\n",
       "      <td>0.844444</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.730769</td>\n",
       "      <td>0.980692</td>\n",
       "      <td>pod.</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.105071</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.961641</td>\n",
       "      <td>0.980392</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.980769</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.961641</td>\n",
       "      <td>0.980392</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.980696</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.961641</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>0.980678</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.961641</td>\n",
       "      <td>0.980392</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.980655</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.978488</td>\n",
       "      <td>0.980392</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.999935</td>\n",
       "      <td>entropy_sampling</td>\n",
       "      <td>0.105148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>14</td>\n",
       "      <td>0.278714</td>\n",
       "      <td>0.620690</td>\n",
       "      <td>0.562500</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.962823</td>\n",
       "      <td>pod.</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.000786</td>\n",
       "      <td>8</td>\n",
       "      <td>20</td>\n",
       "      <td>0.270425</td>\n",
       "      <td>0.562500</td>\n",
       "      <td>0.473684</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.963460</td>\n",
       "      <td>8</td>\n",
       "      <td>17</td>\n",
       "      <td>0.292643</td>\n",
       "      <td>0.590164</td>\n",
       "      <td>0.514286</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.960997</td>\n",
       "      <td>8</td>\n",
       "      <td>17</td>\n",
       "      <td>0.299794</td>\n",
       "      <td>0.590164</td>\n",
       "      <td>0.514286</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.959103</td>\n",
       "      <td>8</td>\n",
       "      <td>17</td>\n",
       "      <td>0.291016</td>\n",
       "      <td>0.590164</td>\n",
       "      <td>0.514286</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.961305</td>\n",
       "      <td>8</td>\n",
       "      <td>17</td>\n",
       "      <td>0.287388</td>\n",
       "      <td>0.590164</td>\n",
       "      <td>0.514286</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.962041</td>\n",
       "      <td>random_sampling</td>\n",
       "      <td>0.040921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>14</td>\n",
       "      <td>0.278714</td>\n",
       "      <td>0.620690</td>\n",
       "      <td>0.562500</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.962823</td>\n",
       "      <td>pod.</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.000842</td>\n",
       "      <td>10</td>\n",
       "      <td>31</td>\n",
       "      <td>0.172081</td>\n",
       "      <td>0.438356</td>\n",
       "      <td>0.340426</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.951999</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>0.357298</td>\n",
       "      <td>0.653846</td>\n",
       "      <td>0.653846</td>\n",
       "      <td>0.653846</td>\n",
       "      <td>0.935945</td>\n",
       "      <td>9</td>\n",
       "      <td>21</td>\n",
       "      <td>0.239003</td>\n",
       "      <td>0.531250</td>\n",
       "      <td>0.447368</td>\n",
       "      <td>0.653846</td>\n",
       "      <td>0.964693</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>0.528213</td>\n",
       "      <td>0.723404</td>\n",
       "      <td>0.809524</td>\n",
       "      <td>0.653846</td>\n",
       "      <td>0.934462</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>0.538120</td>\n",
       "      <td>0.782609</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.969129</td>\n",
       "      <td>entropy_sampling</td>\n",
       "      <td>0.029950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0.826497</td>\n",
       "      <td>0.820513</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.695652</td>\n",
       "      <td>0.912588</td>\n",
       "      <td>nmap.</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.107061</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0.819975</td>\n",
       "      <td>0.647059</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.478261</td>\n",
       "      <td>0.912733</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0.826497</td>\n",
       "      <td>0.820513</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.695652</td>\n",
       "      <td>0.912588</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0.826497</td>\n",
       "      <td>0.820513</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.695652</td>\n",
       "      <td>0.912588</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0.817802</td>\n",
       "      <td>0.647059</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.478261</td>\n",
       "      <td>0.912731</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0.817802</td>\n",
       "      <td>0.647059</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.478261</td>\n",
       "      <td>0.912731</td>\n",
       "      <td>random_sampling</td>\n",
       "      <td>0.111886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0.826497</td>\n",
       "      <td>0.820513</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.695652</td>\n",
       "      <td>0.912588</td>\n",
       "      <td>nmap.</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.103046</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.826497</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.826087</td>\n",
       "      <td>0.912704</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.826497</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.826087</td>\n",
       "      <td>0.912078</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0.826497</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.739130</td>\n",
       "      <td>0.912588</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.822149</td>\n",
       "      <td>0.883721</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>0.826087</td>\n",
       "      <td>0.911895</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.826497</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.826087</td>\n",
       "      <td>0.912632</td>\n",
       "      <td>entropy_sampling</td>\n",
       "      <td>0.106706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12</td>\n",
       "      <td>15</td>\n",
       "      <td>0.299644</td>\n",
       "      <td>0.448980</td>\n",
       "      <td>0.423077</td>\n",
       "      <td>0.478261</td>\n",
       "      <td>0.964120</td>\n",
       "      <td>nmap.</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.000695</td>\n",
       "      <td>11</td>\n",
       "      <td>13</td>\n",
       "      <td>0.344646</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.480000</td>\n",
       "      <td>0.521739</td>\n",
       "      <td>0.964249</td>\n",
       "      <td>12</td>\n",
       "      <td>15</td>\n",
       "      <td>0.301091</td>\n",
       "      <td>0.448980</td>\n",
       "      <td>0.423077</td>\n",
       "      <td>0.478261</td>\n",
       "      <td>0.963981</td>\n",
       "      <td>12</td>\n",
       "      <td>16</td>\n",
       "      <td>0.310364</td>\n",
       "      <td>0.440000</td>\n",
       "      <td>0.407407</td>\n",
       "      <td>0.478261</td>\n",
       "      <td>0.964120</td>\n",
       "      <td>12</td>\n",
       "      <td>15</td>\n",
       "      <td>0.271534</td>\n",
       "      <td>0.448980</td>\n",
       "      <td>0.423077</td>\n",
       "      <td>0.478261</td>\n",
       "      <td>0.964290</td>\n",
       "      <td>12</td>\n",
       "      <td>15</td>\n",
       "      <td>0.280982</td>\n",
       "      <td>0.448980</td>\n",
       "      <td>0.423077</td>\n",
       "      <td>0.478261</td>\n",
       "      <td>0.965729</td>\n",
       "      <td>random_sampling</td>\n",
       "      <td>0.025499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12</td>\n",
       "      <td>15</td>\n",
       "      <td>0.299644</td>\n",
       "      <td>0.448980</td>\n",
       "      <td>0.423077</td>\n",
       "      <td>0.478261</td>\n",
       "      <td>0.964120</td>\n",
       "      <td>nmap.</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.000702</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.828918</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.826087</td>\n",
       "      <td>0.976773</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0.645973</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.608696</td>\n",
       "      <td>0.967378</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>0.486915</td>\n",
       "      <td>0.578947</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.478261</td>\n",
       "      <td>0.968035</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.828757</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.826087</td>\n",
       "      <td>0.975347</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.828628</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.826087</td>\n",
       "      <td>0.974078</td>\n",
       "      <td>entropy_sampling</td>\n",
       "      <td>0.034215</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   initial_FN  initial_FP  initial_average precision  initial_f1  \\\n",
       "0          10           0                   1.000000    0.999822   \n",
       "1          10           0                   1.000000    0.999822   \n",
       "2           9          57                   0.999997    0.998826   \n",
       "3           9          57                   0.999997    0.998826   \n",
       "0           4           0                   1.000000    0.999813   \n",
       "1           4           0                   1.000000    0.999813   \n",
       "2           6           3                   0.999993    0.999580   \n",
       "3           6           3                   0.999993    0.999580   \n",
       "0           2           0                   1.000000    0.995434   \n",
       "1           2           0                   1.000000    0.995434   \n",
       "2           4          24                   0.809557    0.939130   \n",
       "3           4          24                   0.809557    0.939130   \n",
       "0          16           0                   0.990126    0.947020   \n",
       "1          16           0                   0.990126    0.947020   \n",
       "2          17           0                   0.997285    0.943522   \n",
       "3          17           0                   0.997285    0.943522   \n",
       "0           4           0                   0.997280    0.983740   \n",
       "1           4           0                   0.997280    0.983740   \n",
       "2           8          10                   0.931825    0.928571   \n",
       "3           8          10                   0.931825    0.928571   \n",
       "0           2           0                   0.990394    0.990291   \n",
       "1           2           0                   0.990394    0.990291   \n",
       "2         104           0                   0.070932    0.000000   \n",
       "3         104           0                   0.070932    0.000000   \n",
       "0          21           2                   0.941510    0.875676   \n",
       "1          21           2                   0.941510    0.875676   \n",
       "2          20          22                   0.819296    0.796117   \n",
       "3          20          22                   0.819296    0.796117   \n",
       "0           7           0                   1.000000    0.962963   \n",
       "1           7           0                   1.000000    0.962963   \n",
       "2          14           3                   0.971430    0.908108   \n",
       "3          14           3                   0.971430    0.908108   \n",
       "0           7           0                   0.961641    0.844444   \n",
       "1           7           0                   0.961641    0.844444   \n",
       "2           8          14                   0.278714    0.620690   \n",
       "3           8          14                   0.278714    0.620690   \n",
       "0           7           0                   0.826497    0.820513   \n",
       "1           7           0                   0.826497    0.820513   \n",
       "2          12          15                   0.299644    0.448980   \n",
       "3          12          15                   0.299644    0.448980   \n",
       "\n",
       "   initial_precision  initial_recall  initial_roc auc         label  \\\n",
       "0           1.000000        0.999644         1.000000        smurf.   \n",
       "1           1.000000        0.999644         1.000000        smurf.   \n",
       "2           0.997973        0.999679         0.999991        smurf.   \n",
       "3           0.997973        0.999679         0.999991        smurf.   \n",
       "0           1.000000        0.999627         1.000000      neptune.   \n",
       "1           1.000000        0.999627         1.000000      neptune.   \n",
       "2           0.999720        0.999440         0.999992      neptune.   \n",
       "3           0.999720        0.999440         0.999992      neptune.   \n",
       "0           1.000000        0.990909         1.000000         back.   \n",
       "1           1.000000        0.990909         1.000000         back.   \n",
       "2           0.900000        0.981818         0.997958         back.   \n",
       "3           0.900000        0.981818         0.997958         back.   \n",
       "0           1.000000        0.899371         0.999877        satan.   \n",
       "1           1.000000        0.899371         0.999877        satan.   \n",
       "2           1.000000        0.893082         0.999946        satan.   \n",
       "3           1.000000        0.893082         0.999946        satan.   \n",
       "0           1.000000        0.968000         0.999960      ipsweep.   \n",
       "1           1.000000        0.968000         0.999960      ipsweep.   \n",
       "2           0.921260        0.936000         0.998863      ipsweep.   \n",
       "3           0.921260        0.936000         0.998863      ipsweep.   \n",
       "0           1.000000        0.980769         0.995170    portsweep.   \n",
       "1           1.000000        0.980769         0.995170    portsweep.   \n",
       "2           0.000000        0.000000         0.896795    portsweep.   \n",
       "3           0.000000        0.000000         0.896795    portsweep.   \n",
       "0           0.975904        0.794118         0.984869  warezclient.   \n",
       "1           0.975904        0.794118         0.984869  warezclient.   \n",
       "2           0.788462        0.803922         0.920803  warezclient.   \n",
       "3           0.788462        0.803922         0.920803  warezclient.   \n",
       "0           1.000000        0.928571         1.000000     teardrop.   \n",
       "1           1.000000        0.928571         1.000000     teardrop.   \n",
       "2           0.965517        0.857143         0.999575     teardrop.   \n",
       "3           0.965517        0.857143         0.999575     teardrop.   \n",
       "0           1.000000        0.730769         0.980692          pod.   \n",
       "1           1.000000        0.730769         0.980692          pod.   \n",
       "2           0.562500        0.692308         0.962823          pod.   \n",
       "3           0.562500        0.692308         0.962823          pod.   \n",
       "0           1.000000        0.695652         0.912588         nmap.   \n",
       "1           1.000000        0.695652         0.912588         nmap.   \n",
       "2           0.423077        0.478261         0.964120         nmap.   \n",
       "3           0.423077        0.478261         0.964120         nmap.   \n",
       "\n",
       "                  learner  query time (s)  sample_100_FN  sample_100_FP  \\\n",
       "0  RandomForestClassifier        0.113536             12              0   \n",
       "1  RandomForestClassifier        0.111460              0              0   \n",
       "2      LogisticRegression        0.002383              9              6   \n",
       "3      LogisticRegression        0.002559              0              0   \n",
       "0  RandomForestClassifier        0.112695              3              0   \n",
       "1  RandomForestClassifier        0.112593              1              0   \n",
       "2      LogisticRegression        0.001880              6              2   \n",
       "3      LogisticRegression        0.002293              1              0   \n",
       "0  RandomForestClassifier        0.109122              2              0   \n",
       "1  RandomForestClassifier        0.104424              0              0   \n",
       "2      LogisticRegression        0.000712             44             13   \n",
       "3      LogisticRegression        0.000772              5             19   \n",
       "0  RandomForestClassifier        0.105923             17              0   \n",
       "1  RandomForestClassifier        0.105800              0              0   \n",
       "2      LogisticRegression        0.001129             17              0   \n",
       "3      LogisticRegression        0.000904              1              1   \n",
       "0  RandomForestClassifier        0.102991              4              0   \n",
       "1  RandomForestClassifier        0.103194              0              0   \n",
       "2      LogisticRegression        0.000936              8             13   \n",
       "3      LogisticRegression        0.000780              0              0   \n",
       "0  RandomForestClassifier        0.108250              9              0   \n",
       "1  RandomForestClassifier        0.105511              1              0   \n",
       "2      LogisticRegression        0.000972            104              0   \n",
       "3      LogisticRegression        0.001048             14            101   \n",
       "0  RandomForestClassifier        0.106202             16              2   \n",
       "1  RandomForestClassifier        0.105443              5              0   \n",
       "2      LogisticRegression        0.000847             17             26   \n",
       "3      LogisticRegression        0.000743             15              2   \n",
       "0  RandomForestClassifier        0.105159              4              1   \n",
       "1  RandomForestClassifier        0.106465              0              0   \n",
       "2      LogisticRegression        0.000979             13              4   \n",
       "3      LogisticRegression        0.000985              0              0   \n",
       "0  RandomForestClassifier        0.104013             16              0   \n",
       "1  RandomForestClassifier        0.105071              1              0   \n",
       "2      LogisticRegression        0.000786              8             20   \n",
       "3      LogisticRegression        0.000842             10             31   \n",
       "0  RandomForestClassifier        0.107061             12              0   \n",
       "1  RandomForestClassifier        0.103046              4              0   \n",
       "2      LogisticRegression        0.000695             11             13   \n",
       "3      LogisticRegression        0.000702              4              0   \n",
       "\n",
       "   sample_100_average precision  sample_100_f1  sample_100_precision  \\\n",
       "0                      1.000000       0.999786              1.000000   \n",
       "1                      1.000000       1.000000              1.000000   \n",
       "2                      0.999799       0.999733              0.999786   \n",
       "3                      1.000000       1.000000              1.000000   \n",
       "0                      1.000000       0.999860              1.000000   \n",
       "1                      1.000000       0.999953              1.000000   \n",
       "2                      0.999994       0.999627              0.999813   \n",
       "3                      1.000000       0.999953              1.000000   \n",
       "0                      1.000000       0.995434              1.000000   \n",
       "1                      1.000000       1.000000              1.000000   \n",
       "2                      0.841507       0.860636              0.931217   \n",
       "3                      0.845314       0.947137              0.918803   \n",
       "0                      0.951424       0.943522              1.000000   \n",
       "1                      1.000000       1.000000              1.000000   \n",
       "2                      0.997233       0.943522              1.000000   \n",
       "3                      0.999699       0.993711              0.993711   \n",
       "0                      0.998426       0.983740              1.000000   \n",
       "1                      1.000000       1.000000              1.000000   \n",
       "2                      0.871723       0.917647              0.900000   \n",
       "3                      1.000000       1.000000              1.000000   \n",
       "0                      0.989747       0.954774              1.000000   \n",
       "1                      0.990486       0.995169              1.000000   \n",
       "2                      0.421563       0.000000              0.000000   \n",
       "3                      0.900571       0.610169              0.471204   \n",
       "0                      0.939357       0.905263              0.977273   \n",
       "1                      0.977429       0.974874              1.000000   \n",
       "2                      0.791339       0.798122              0.765766   \n",
       "3                      0.869828       0.910995              0.977528   \n",
       "0                      0.998728       0.974093              0.989474   \n",
       "1                      1.000000       1.000000              1.000000   \n",
       "2                      0.973046       0.909091              0.955056   \n",
       "3                      1.000000       1.000000              1.000000   \n",
       "0                      0.961641       0.555556              1.000000   \n",
       "1                      0.961641       0.980392              1.000000   \n",
       "2                      0.270425       0.562500              0.473684   \n",
       "3                      0.172081       0.438356              0.340426   \n",
       "0                      0.819975       0.647059              1.000000   \n",
       "1                      0.826497       0.904762              1.000000   \n",
       "2                      0.344646       0.500000              0.480000   \n",
       "3                      0.828918       0.904762              1.000000   \n",
       "\n",
       "   sample_100_recall  sample_100_roc auc  sample_10_FN  sample_10_FP  \\\n",
       "0           0.999573            1.000000            10             0   \n",
       "1           1.000000            1.000000             0             0   \n",
       "2           0.999679            0.999891             9             5   \n",
       "3           1.000000            1.000000             1             7   \n",
       "0           0.999720            1.000000             4             0   \n",
       "1           0.999907            1.000000             1             0   \n",
       "2           0.999440            0.999993             6             2   \n",
       "3           0.999907            1.000000             6             8   \n",
       "0           0.990909            1.000000             3             0   \n",
       "1           1.000000            1.000000             0             0   \n",
       "2           0.800000            0.993959             4            25   \n",
       "3           0.977273            0.997945             5            24   \n",
       "0           0.893082            0.977850            17             0   \n",
       "1           1.000000            1.000000             5             0   \n",
       "2           0.893082            0.999944            17             0   \n",
       "3           0.993711            0.999995             2             9   \n",
       "0           0.968000            0.999988             4             0   \n",
       "1           1.000000            1.000000             1             0   \n",
       "2           0.936000            0.998775             8            12   \n",
       "3           1.000000            1.000000             3             0   \n",
       "0           0.913462            0.995164             2             0   \n",
       "1           0.990385            0.995178             2             0   \n",
       "2           0.000000            0.954305            97             0   \n",
       "3           0.865385            0.997089            93             1   \n",
       "0           0.843137            0.979797            21             2   \n",
       "1           0.950980            0.999635             7             1   \n",
       "2           0.833333            0.920601            18            13   \n",
       "3           0.852941            0.947082            15             7   \n",
       "0           0.959184            0.999992             7             0   \n",
       "1           1.000000            1.000000             0             0   \n",
       "2           0.867347            0.999634            12             3   \n",
       "3           1.000000            1.000000             2             0   \n",
       "0           0.384615            0.980755             7             0   \n",
       "1           0.961538            0.980769             1             0   \n",
       "2           0.692308            0.963460             8            17   \n",
       "3           0.615385            0.951999             9             9   \n",
       "0           0.478261            0.912733             7             0   \n",
       "1           0.826087            0.912704             4             0   \n",
       "2           0.521739            0.964249            12            15   \n",
       "3           0.826087            0.976773             9             1   \n",
       "\n",
       "   sample_10_average precision  sample_10_f1  sample_10_precision  \\\n",
       "0                     1.000000      0.999822             1.000000   \n",
       "1                     1.000000      1.000000             1.000000   \n",
       "2                     0.999998      0.999751             0.999822   \n",
       "3                     1.000000      0.999858             0.999751   \n",
       "0                     1.000000      0.999813             1.000000   \n",
       "1                     1.000000      0.999953             1.000000   \n",
       "2                     0.999994      0.999627             0.999813   \n",
       "3                     0.999870      0.999347             0.999254   \n",
       "0                     1.000000      0.993135             1.000000   \n",
       "1                     1.000000      1.000000             1.000000   \n",
       "2                     0.804823      0.937093             0.896266   \n",
       "3                     0.821783      0.936819             0.899582   \n",
       "0                     0.990345      0.943522             1.000000   \n",
       "1                     0.997102      0.984026             1.000000   \n",
       "2                     0.997285      0.943522             1.000000   \n",
       "3                     0.991531      0.966154             0.945783   \n",
       "0                     0.997280      0.983740             1.000000   \n",
       "1                     1.000000      0.995984             1.000000   \n",
       "2                     0.874442      0.921260             0.906977   \n",
       "3                     0.985864      0.987854             1.000000   \n",
       "0                     0.990394      0.990291             1.000000   \n",
       "1                     0.990486      0.990291             1.000000   \n",
       "2                     0.276677      0.126126             1.000000   \n",
       "3                     0.480969      0.189655             0.916667   \n",
       "0                     0.950928      0.875676             0.975904   \n",
       "1                     0.964411      0.959596             0.989583   \n",
       "2                     0.817287      0.844221             0.865979   \n",
       "3                     0.857007      0.887755             0.925532   \n",
       "0                     1.000000      0.962963             1.000000   \n",
       "1                     1.000000      1.000000             1.000000   \n",
       "2                     0.977824      0.919786             0.966292   \n",
       "3                     1.000000      0.989691             1.000000   \n",
       "0                     0.961641      0.844444             1.000000   \n",
       "1                     0.961641      0.980392             1.000000   \n",
       "2                     0.292643      0.590164             0.514286   \n",
       "3                     0.357298      0.653846             0.653846   \n",
       "0                     0.826497      0.820513             1.000000   \n",
       "1                     0.826497      0.904762             1.000000   \n",
       "2                     0.301091      0.448980             0.423077   \n",
       "3                     0.645973      0.736842             0.933333   \n",
       "\n",
       "   sample_10_recall  sample_10_roc auc  sample_1_FN  sample_1_FP  \\\n",
       "0          0.999644           1.000000           10            0   \n",
       "1          1.000000           1.000000            6            0   \n",
       "2          0.999679           0.999995            9           67   \n",
       "3          0.999964           1.000000            9            3   \n",
       "0          0.999627           1.000000            4            0   \n",
       "1          0.999907           1.000000            4            0   \n",
       "2          0.999440           0.999993            6            2   \n",
       "3          0.999440           0.999922            5            1   \n",
       "0          0.986364           1.000000            2            0   \n",
       "1          1.000000           1.000000            4            0   \n",
       "2          0.981818           0.997880            5           22   \n",
       "3          0.977273           0.998050            4           23   \n",
       "0          0.893082           0.999888           16            0   \n",
       "1          0.968553           0.999961           16            0   \n",
       "2          0.893082           0.999946           17            0   \n",
       "3          0.987421           0.999918           15            0   \n",
       "0          0.968000           0.999960            4            0   \n",
       "1          0.992000           1.000000            4            0   \n",
       "2          0.936000           0.998763            8           11   \n",
       "3          0.976000           0.998261            8           11   \n",
       "0          0.980769           0.995170            2            0   \n",
       "1          0.980769           0.995172            3            0   \n",
       "2          0.067308           0.981104          104            0   \n",
       "3          0.105769           0.943884           97            0   \n",
       "0          0.794118           0.994649           21            2   \n",
       "1          0.931373           0.994499           17            2   \n",
       "2          0.823529           0.920969           17            9   \n",
       "3          0.852941           0.950134           16           11   \n",
       "0          0.928571           1.000000            7            0   \n",
       "1          1.000000           1.000000            4            0   \n",
       "2          0.877551           0.999716           14            4   \n",
       "3          0.979592           1.000000           10            3   \n",
       "0          0.730769           0.980692            7            0   \n",
       "1          0.961538           0.980696            4            0   \n",
       "2          0.692308           0.960997            8           17   \n",
       "3          0.653846           0.935945            9           21   \n",
       "0          0.695652           0.912588            7            0   \n",
       "1          0.826087           0.912078            6            0   \n",
       "2          0.478261           0.963981           12           16   \n",
       "3          0.608696           0.967378           12            4   \n",
       "\n",
       "   sample_1_average precision  sample_1_f1  sample_1_precision  \\\n",
       "0                    1.000000     0.999822            1.000000   \n",
       "1                    1.000000     0.999893            1.000000   \n",
       "2                    0.999922     0.998648            0.997619   \n",
       "3                    0.999818     0.999786            0.999893   \n",
       "0                    1.000000     0.999813            1.000000   \n",
       "1                    1.000000     0.999813            1.000000   \n",
       "2                    0.999994     0.999627            0.999813   \n",
       "3                    0.999996     0.999720            0.999907   \n",
       "0                    1.000000     0.995434            1.000000   \n",
       "1                    1.000000     0.990826            1.000000   \n",
       "2                    0.831127     0.940919            0.907173   \n",
       "3                    0.817392     0.941176            0.903766   \n",
       "0                    0.990126     0.947020            1.000000   \n",
       "1                    0.987498     0.947020            1.000000   \n",
       "2                    0.997285     0.943522            1.000000   \n",
       "3                    0.994933     0.950495            1.000000   \n",
       "0                    0.997280     0.983740            1.000000   \n",
       "1                    0.997330     0.983740            1.000000   \n",
       "2                    0.871534     0.924901            0.914062   \n",
       "3                    0.875916     0.924901            0.914062   \n",
       "0                    0.990394     0.990291            1.000000   \n",
       "1                    0.990214     0.985366            1.000000   \n",
       "2                    0.065582     0.000000            0.000000   \n",
       "3                    0.528734     0.126126            1.000000   \n",
       "0                    0.950928     0.875676            0.975904   \n",
       "1                    0.950295     0.899471            0.977011   \n",
       "2                    0.788670     0.867347            0.904255   \n",
       "3                    0.821069     0.864322            0.886598   \n",
       "0                    1.000000     0.962963            1.000000   \n",
       "1                    1.000000     0.979167            1.000000   \n",
       "2                    0.963902     0.903226            0.954545   \n",
       "3                    0.979303     0.931217            0.967033   \n",
       "0                    0.961641     0.844444            1.000000   \n",
       "1                    0.961641     0.916667            1.000000   \n",
       "2                    0.299794     0.590164            0.514286   \n",
       "3                    0.239003     0.531250            0.447368   \n",
       "0                    0.826497     0.820513            1.000000   \n",
       "1                    0.826497     0.850000            1.000000   \n",
       "2                    0.310364     0.440000            0.407407   \n",
       "3                    0.486915     0.578947            0.733333   \n",
       "\n",
       "   sample_1_recall  sample_1_roc auc  sample_25_FN  sample_25_FP  \\\n",
       "0         0.999644          1.000000            12             0   \n",
       "1         0.999786          1.000000             0             0   \n",
       "2         0.999679          0.999886             9             6   \n",
       "3         0.999679          0.999888             1             5   \n",
       "0         0.999627          1.000000             3             0   \n",
       "1         0.999627          1.000000             1             0   \n",
       "2         0.999440          0.999993             6             2   \n",
       "3         0.999534          0.999995             2             0   \n",
       "0         0.990909          1.000000             0             0   \n",
       "1         0.981818          1.000000             0             0   \n",
       "2         0.977273          0.998045             5            19   \n",
       "3         0.981818          0.998180             4            19   \n",
       "0         0.899371          0.999877            17             0   \n",
       "1         0.899371          0.999831             0             0   \n",
       "2         0.893082          0.999946            17             0   \n",
       "3         0.905660          0.999885             1             1   \n",
       "0         0.968000          0.999960             4             3   \n",
       "1         0.968000          0.999961             1             0   \n",
       "2         0.936000          0.998797             8            12   \n",
       "3         0.936000          0.998791             2             0   \n",
       "0         0.980769          0.995170             9             0   \n",
       "1         0.971154          0.995167             1             0   \n",
       "2         0.000000          0.880780            93             3   \n",
       "3         0.067308          0.993985            93             1   \n",
       "0         0.794118          0.994649            29             2   \n",
       "1         0.833333          0.994624             7             2   \n",
       "2         0.833333          0.922778            16            10   \n",
       "3         0.843137          0.923721            15             7   \n",
       "0         0.928571          1.000000            11             0   \n",
       "1         0.959184          1.000000             3             0   \n",
       "2         0.857143          0.999464            16             6   \n",
       "3         0.897959          0.999687             0             0   \n",
       "0         0.730769          0.980692            16             0   \n",
       "1         0.846154          0.980678             1             0   \n",
       "2         0.692308          0.959103             8            17   \n",
       "3         0.653846          0.964693             9             4   \n",
       "0         0.695652          0.912588            12             0   \n",
       "1         0.739130          0.912588             4             1   \n",
       "2         0.478261          0.964120            12            15   \n",
       "3         0.478261          0.968035             4             0   \n",
       "\n",
       "   sample_25_average precision  sample_25_f1  sample_25_precision  \\\n",
       "0                     1.000000      0.999786             1.000000   \n",
       "1                     1.000000      1.000000             1.000000   \n",
       "2                     0.999798      0.999733             0.999786   \n",
       "3                     0.999820      0.999893             0.999822   \n",
       "0                     1.000000      0.999860             1.000000   \n",
       "1                     1.000000      0.999953             1.000000   \n",
       "2                     0.999993      0.999627             0.999813   \n",
       "3                     1.000000      0.999907             1.000000   \n",
       "0                     1.000000      1.000000             1.000000   \n",
       "1                     1.000000      1.000000             1.000000   \n",
       "2                     0.830619      0.947137             0.918803   \n",
       "3                     0.842252      0.949451             0.919149   \n",
       "0                     0.951424      0.943522             1.000000   \n",
       "1                     1.000000      1.000000             1.000000   \n",
       "2                     0.997257      0.943522             1.000000   \n",
       "3                     0.994705      0.993711             0.993711   \n",
       "0                     0.995468      0.971888             0.975806   \n",
       "1                     0.999634      0.995984             1.000000   \n",
       "2                     0.869079      0.921260             0.906977   \n",
       "3                     0.993155      0.991935             1.000000   \n",
       "0                     0.989747      0.954774             1.000000   \n",
       "1                     0.990486      0.995169             1.000000   \n",
       "2                     0.510700      0.186441             0.785714   \n",
       "3                     0.464382      0.189655             0.916667   \n",
       "0                     0.918023      0.824859             0.973333   \n",
       "1                     0.964004      0.954774             0.979381   \n",
       "2                     0.821141      0.868687             0.895833   \n",
       "3                     0.874303      0.887755             0.925532   \n",
       "0                     0.999691      0.940541             1.000000   \n",
       "1                     1.000000      0.984456             1.000000   \n",
       "2                     0.953266      0.881720             0.931818   \n",
       "3                     1.000000      1.000000             1.000000   \n",
       "0                     0.961641      0.555556             1.000000   \n",
       "1                     0.961641      0.980392             1.000000   \n",
       "2                     0.291016      0.590164             0.514286   \n",
       "3                     0.528213      0.723404             0.809524   \n",
       "0                     0.817802      0.647059             1.000000   \n",
       "1                     0.822149      0.883721             0.950000   \n",
       "2                     0.271534      0.448980             0.423077   \n",
       "3                     0.828757      0.904762             1.000000   \n",
       "\n",
       "   sample_25_recall  sample_25_roc auc  sample_50_FN  sample_50_FP  \\\n",
       "0          0.999573           1.000000            12             0   \n",
       "1          1.000000           1.000000             0             0   \n",
       "2          0.999679           0.999890             9             4   \n",
       "3          0.999964           0.999793             0             2   \n",
       "0          0.999720           1.000000             3             0   \n",
       "1          0.999907           1.000000             1             0   \n",
       "2          0.999440           0.999992             5             1   \n",
       "3          0.999813           1.000000             1             0   \n",
       "0          1.000000           1.000000             0             0   \n",
       "1          1.000000           1.000000             1             0   \n",
       "2          0.977273           0.997239             6            20   \n",
       "3          0.981818           0.998661             5            19   \n",
       "0          0.893082           0.977850            17             0   \n",
       "1          1.000000           1.000000             0             0   \n",
       "2          0.893082           0.999945            17             0   \n",
       "3          0.993711           0.999452             1             2   \n",
       "0          0.968000           0.999943             4             0   \n",
       "1          0.992000           0.999998             1             0   \n",
       "2          0.936000           0.998792             8            11   \n",
       "3          0.984000           0.999391             1             0   \n",
       "0          0.913462           0.995164             9             0   \n",
       "1          0.990385           0.995178             1             0   \n",
       "2          0.105769           0.946361           104             0   \n",
       "3          0.105769           0.963702           104             0   \n",
       "0          0.715686           0.974589            26             1   \n",
       "1          0.931373           0.999211             5             1   \n",
       "2          0.843137           0.923408            16            16   \n",
       "3          0.852941           0.926187            15             3   \n",
       "0          0.887755           0.999998             3             0   \n",
       "1          0.969388           1.000000             0             0   \n",
       "2          0.836735           0.999318            12             7   \n",
       "3          1.000000           1.000000             0             0   \n",
       "0          0.384615           0.980755            16             0   \n",
       "1          0.961538           0.980655             1             0   \n",
       "2          0.692308           0.961305             8            17   \n",
       "3          0.653846           0.934462             8             2   \n",
       "0          0.478261           0.912731            12             0   \n",
       "1          0.826087           0.911895             4             0   \n",
       "2          0.478261           0.964290            12            15   \n",
       "3          0.826087           0.975347             4             0   \n",
       "\n",
       "   sample_50_average precision  sample_50_f1  sample_50_precision  \\\n",
       "0                     1.000000      0.999786             1.000000   \n",
       "1                     1.000000      1.000000             1.000000   \n",
       "2                     0.999805      0.999768             0.999858   \n",
       "3                     1.000000      0.999964             0.999929   \n",
       "0                     1.000000      0.999860             1.000000   \n",
       "1                     1.000000      0.999953             1.000000   \n",
       "2                     0.999996      0.999720             0.999907   \n",
       "3                     1.000000      0.999953             1.000000   \n",
       "0                     1.000000      1.000000             1.000000   \n",
       "1                     1.000000      0.997722             1.000000   \n",
       "2                     0.828801      0.942731             0.914530   \n",
       "3                     0.835839      0.947137             0.918803   \n",
       "0                     0.951424      0.943522             1.000000   \n",
       "1                     1.000000      1.000000             1.000000   \n",
       "2                     0.997233      0.943522             1.000000   \n",
       "3                     0.994886      0.990596             0.987500   \n",
       "0                     0.999250      0.983740             1.000000   \n",
       "1                     1.000000      0.995984             1.000000   \n",
       "2                     0.876126      0.924901             0.914062   \n",
       "3                     0.996878      0.995984             1.000000   \n",
       "0                     0.989747      0.954774             1.000000   \n",
       "1                     0.990486      0.995169             1.000000   \n",
       "2                     0.380633      0.000000             0.000000   \n",
       "3                     0.113923      0.000000             0.000000   \n",
       "0                     0.916512      0.849162             0.987013   \n",
       "1                     0.971608      0.970000             0.989796   \n",
       "2                     0.773538      0.843137             0.843137   \n",
       "3                     0.868548      0.906250             0.966667   \n",
       "0                     0.999691      0.984456             1.000000   \n",
       "1                     1.000000      1.000000             1.000000   \n",
       "2                     0.945192      0.900524             0.924731   \n",
       "3                     1.000000      1.000000             1.000000   \n",
       "0                     0.961641      0.555556             1.000000   \n",
       "1                     0.978488      0.980392             1.000000   \n",
       "2                     0.287388      0.590164             0.514286   \n",
       "3                     0.538120      0.782609             0.900000   \n",
       "0                     0.817802      0.647059             1.000000   \n",
       "1                     0.826497      0.904762             1.000000   \n",
       "2                     0.280982      0.448980             0.423077   \n",
       "3                     0.828628      0.904762             1.000000   \n",
       "\n",
       "   sample_50_recall  sample_50_roc auc sampling strategy  train time (s)  \n",
       "0          0.999573           1.000000   random_sampling        0.105282  \n",
       "1          1.000000           1.000000  entropy_sampling        0.109376  \n",
       "2          0.999679           0.999890   random_sampling        0.024312  \n",
       "3          1.000000           1.000000  entropy_sampling        0.026511  \n",
       "0          0.999720           1.000000   random_sampling        0.109523  \n",
       "1          0.999907           1.000000  entropy_sampling        0.108728  \n",
       "2          0.999534           0.999996   random_sampling        0.024976  \n",
       "3          0.999907           1.000000  entropy_sampling        0.026525  \n",
       "0          1.000000           1.000000   random_sampling        0.105342  \n",
       "1          0.995455           1.000000  entropy_sampling        0.110879  \n",
       "2          0.972727           0.996983   random_sampling        0.034752  \n",
       "3          0.977273           0.998291  entropy_sampling        0.033389  \n",
       "0          0.893082           0.977850   random_sampling        0.110261  \n",
       "1          1.000000           1.000000  entropy_sampling        0.110374  \n",
       "2          0.893082           0.999944   random_sampling        0.032182  \n",
       "3          0.993711           0.999553  entropy_sampling        0.027748  \n",
       "0          0.968000           0.999995   random_sampling        0.109571  \n",
       "1          0.992000           1.000000  entropy_sampling        0.107601  \n",
       "2          0.936000           0.998799   random_sampling        0.028906  \n",
       "3          0.992000           0.999934  entropy_sampling        0.032190  \n",
       "0          0.913462           0.995164   random_sampling        0.107740  \n",
       "1          0.990385           0.995173  entropy_sampling        0.110793  \n",
       "2          0.000000           0.953418   random_sampling        0.024480  \n",
       "3          0.000000           0.905436  entropy_sampling        0.024552  \n",
       "0          0.745098           0.974607   random_sampling        0.109358  \n",
       "1          0.950980           0.999500  entropy_sampling        0.109547  \n",
       "2          0.843137           0.922300   random_sampling        0.033755  \n",
       "3          0.852941           0.930463  entropy_sampling        0.039316  \n",
       "0          0.969388           0.999998   random_sampling        0.110035  \n",
       "1          1.000000           1.000000  entropy_sampling        0.110045  \n",
       "2          0.877551           0.999419   random_sampling        0.045063  \n",
       "3          1.000000           1.000000  entropy_sampling        0.030475  \n",
       "0          0.384615           0.980755   random_sampling        0.110185  \n",
       "1          0.961538           0.999935  entropy_sampling        0.105148  \n",
       "2          0.692308           0.962041   random_sampling        0.040921  \n",
       "3          0.692308           0.969129  entropy_sampling        0.029950  \n",
       "0          0.478261           0.912731   random_sampling        0.111886  \n",
       "1          0.826087           0.912632  entropy_sampling        0.106706  \n",
       "2          0.478261           0.965729   random_sampling        0.025499  \n",
       "3          0.826087           0.974078  entropy_sampling        0.034215  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_active_learning = ni.report_active_learning()\n",
    "df_active_learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">initial_FN</th>\n",
       "      <th colspan=\"2\" halign=\"left\">initial_FP</th>\n",
       "      <th colspan=\"2\" halign=\"left\">initial_average precision</th>\n",
       "      <th colspan=\"2\" halign=\"left\">initial_f1</th>\n",
       "      <th colspan=\"2\" halign=\"left\">initial_precision</th>\n",
       "      <th colspan=\"2\" halign=\"left\">initial_recall</th>\n",
       "      <th colspan=\"2\" halign=\"left\">initial_roc auc</th>\n",
       "      <th colspan=\"2\" halign=\"left\">query time (s)</th>\n",
       "      <th colspan=\"2\" halign=\"left\">sample_100_FN</th>\n",
       "      <th colspan=\"2\" halign=\"left\">sample_100_FP</th>\n",
       "      <th colspan=\"2\" halign=\"left\">sample_100_average precision</th>\n",
       "      <th colspan=\"2\" halign=\"left\">sample_100_f1</th>\n",
       "      <th colspan=\"2\" halign=\"left\">sample_100_precision</th>\n",
       "      <th colspan=\"2\" halign=\"left\">sample_100_recall</th>\n",
       "      <th colspan=\"2\" halign=\"left\">sample_100_roc auc</th>\n",
       "      <th colspan=\"2\" halign=\"left\">sample_10_FN</th>\n",
       "      <th colspan=\"2\" halign=\"left\">sample_10_FP</th>\n",
       "      <th colspan=\"2\" halign=\"left\">sample_10_average precision</th>\n",
       "      <th colspan=\"2\" halign=\"left\">sample_10_f1</th>\n",
       "      <th colspan=\"2\" halign=\"left\">sample_10_precision</th>\n",
       "      <th colspan=\"2\" halign=\"left\">sample_10_recall</th>\n",
       "      <th colspan=\"2\" halign=\"left\">sample_10_roc auc</th>\n",
       "      <th colspan=\"2\" halign=\"left\">sample_1_FN</th>\n",
       "      <th colspan=\"2\" halign=\"left\">sample_1_FP</th>\n",
       "      <th colspan=\"2\" halign=\"left\">sample_1_average precision</th>\n",
       "      <th colspan=\"2\" halign=\"left\">sample_1_f1</th>\n",
       "      <th colspan=\"2\" halign=\"left\">sample_1_precision</th>\n",
       "      <th colspan=\"2\" halign=\"left\">sample_1_recall</th>\n",
       "      <th colspan=\"2\" halign=\"left\">sample_1_roc auc</th>\n",
       "      <th colspan=\"2\" halign=\"left\">sample_25_FN</th>\n",
       "      <th colspan=\"2\" halign=\"left\">sample_25_FP</th>\n",
       "      <th colspan=\"2\" halign=\"left\">sample_25_average precision</th>\n",
       "      <th colspan=\"2\" halign=\"left\">sample_25_f1</th>\n",
       "      <th colspan=\"2\" halign=\"left\">sample_25_precision</th>\n",
       "      <th colspan=\"2\" halign=\"left\">sample_25_recall</th>\n",
       "      <th colspan=\"2\" halign=\"left\">sample_25_roc auc</th>\n",
       "      <th colspan=\"2\" halign=\"left\">sample_50_FN</th>\n",
       "      <th colspan=\"2\" halign=\"left\">sample_50_FP</th>\n",
       "      <th colspan=\"2\" halign=\"left\">sample_50_average precision</th>\n",
       "      <th colspan=\"2\" halign=\"left\">sample_50_f1</th>\n",
       "      <th colspan=\"2\" halign=\"left\">sample_50_precision</th>\n",
       "      <th colspan=\"2\" halign=\"left\">sample_50_recall</th>\n",
       "      <th colspan=\"2\" halign=\"left\">sample_50_roc auc</th>\n",
       "      <th colspan=\"2\" halign=\"left\">train time (s)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>learner</th>\n",
       "      <th>sampling strategy</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">LogisticRegression</th>\n",
       "      <th>entropy_sampling</th>\n",
       "      <td>20.2</td>\n",
       "      <td>29.86</td>\n",
       "      <td>14.8</td>\n",
       "      <td>17.18</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.91</td>\n",
       "      <td>15.4</td>\n",
       "      <td>31.90</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.02</td>\n",
       "      <td>14.5</td>\n",
       "      <td>27.91</td>\n",
       "      <td>6.6</td>\n",
       "      <td>7.20</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.03</td>\n",
       "      <td>18.5</td>\n",
       "      <td>27.85</td>\n",
       "      <td>7.7</td>\n",
       "      <td>8.53</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.03</td>\n",
       "      <td>13.1</td>\n",
       "      <td>28.44</td>\n",
       "      <td>3.7</td>\n",
       "      <td>5.93</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.03</td>\n",
       "      <td>13.9</td>\n",
       "      <td>32.00</td>\n",
       "      <td>2.8</td>\n",
       "      <td>5.81</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>random_sampling</th>\n",
       "      <td>20.2</td>\n",
       "      <td>29.86</td>\n",
       "      <td>14.8</td>\n",
       "      <td>17.18</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.7</td>\n",
       "      <td>30.27</td>\n",
       "      <td>9.7</td>\n",
       "      <td>8.81</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.03</td>\n",
       "      <td>19.1</td>\n",
       "      <td>27.73</td>\n",
       "      <td>9.2</td>\n",
       "      <td>8.46</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.03</td>\n",
       "      <td>20.0</td>\n",
       "      <td>29.82</td>\n",
       "      <td>14.8</td>\n",
       "      <td>19.86</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.04</td>\n",
       "      <td>19.0</td>\n",
       "      <td>26.36</td>\n",
       "      <td>9.0</td>\n",
       "      <td>6.62</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.03</td>\n",
       "      <td>19.7</td>\n",
       "      <td>29.89</td>\n",
       "      <td>9.1</td>\n",
       "      <td>7.67</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">RandomForestClassifier</th>\n",
       "      <th>entropy_sampling</th>\n",
       "      <td>8.0</td>\n",
       "      <td>6.18</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.07</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.81</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.03</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.03</td>\n",
       "      <td>2.1</td>\n",
       "      <td>2.42</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.03</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.03</td>\n",
       "      <td>6.8</td>\n",
       "      <td>5.20</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.05</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.03</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2.25</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.03</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.71</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.03</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>random_sampling</th>\n",
       "      <td>8.0</td>\n",
       "      <td>6.18</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.07</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.5</td>\n",
       "      <td>5.89</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.16</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.03</td>\n",
       "      <td>8.2</td>\n",
       "      <td>6.23</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.07</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.03</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6.18</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.07</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.03</td>\n",
       "      <td>11.3</td>\n",
       "      <td>8.33</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.08</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.03</td>\n",
       "      <td>10.2</td>\n",
       "      <td>8.05</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.16</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         initial_FN        initial_FP         \\\n",
       "                                               mean    std       mean    std   \n",
       "learner                sampling strategy                                       \n",
       "LogisticRegression     entropy_sampling        20.2  29.86       14.8  17.18   \n",
       "                       random_sampling         20.2  29.86       14.8  17.18   \n",
       "RandomForestClassifier entropy_sampling         8.0   6.18        0.2   0.63   \n",
       "                       random_sampling          8.0   6.18        0.2   0.63   \n",
       "\n",
       "                                         initial_average precision        \\\n",
       "                                                              mean   std   \n",
       "learner                sampling strategy                                   \n",
       "LogisticRegression     entropy_sampling                       0.72  0.36   \n",
       "                       random_sampling                        0.72  0.36   \n",
       "RandomForestClassifier entropy_sampling                       0.97  0.05   \n",
       "                       random_sampling                        0.97  0.05   \n",
       "\n",
       "                                         initial_f1       initial_precision  \\\n",
       "                                               mean   std              mean   \n",
       "learner                sampling strategy                                      \n",
       "LogisticRegression     entropy_sampling        0.76  0.32              0.76   \n",
       "                       random_sampling         0.76  0.32              0.76   \n",
       "RandomForestClassifier entropy_sampling        0.94  0.07              1.00   \n",
       "                       random_sampling         0.94  0.07              1.00   \n",
       "\n",
       "                                               initial_recall        \\\n",
       "                                           std           mean   std   \n",
       "learner                sampling strategy                              \n",
       "LogisticRegression     entropy_sampling   0.33           0.76  0.31   \n",
       "                       random_sampling    0.33           0.76  0.31   \n",
       "RandomForestClassifier entropy_sampling   0.01           0.90  0.12   \n",
       "                       random_sampling    0.01           0.90  0.12   \n",
       "\n",
       "                                         initial_roc auc       query time (s)  \\\n",
       "                                                    mean   std           mean   \n",
       "learner                sampling strategy                                        \n",
       "LogisticRegression     entropy_sampling             0.97  0.04           0.00   \n",
       "                       random_sampling              0.97  0.04           0.00   \n",
       "RandomForestClassifier entropy_sampling             0.99  0.03           0.11   \n",
       "                       random_sampling              0.99  0.03           0.11   \n",
       "\n",
       "                                              sample_100_FN         \\\n",
       "                                          std          mean    std   \n",
       "learner                sampling strategy                             \n",
       "LogisticRegression     entropy_sampling   0.0           5.0   5.91   \n",
       "                       random_sampling    0.0          23.7  30.27   \n",
       "RandomForestClassifier entropy_sampling   0.0           1.2   1.81   \n",
       "                       random_sampling    0.0           9.5   5.89   \n",
       "\n",
       "                                         sample_100_FP         \\\n",
       "                                                  mean    std   \n",
       "learner                sampling strategy                        \n",
       "LogisticRegression     entropy_sampling           15.4  31.90   \n",
       "                       random_sampling             9.7   8.81   \n",
       "RandomForestClassifier entropy_sampling            0.0   0.00   \n",
       "                       random_sampling             0.3   0.67   \n",
       "\n",
       "                                         sample_100_average precision        \\\n",
       "                                                                 mean   std   \n",
       "learner                sampling strategy                                      \n",
       "LogisticRegression     entropy_sampling                          0.86  0.25   \n",
       "                       random_sampling                           0.75  0.29   \n",
       "RandomForestClassifier entropy_sampling                          0.98  0.05   \n",
       "                       random_sampling                           0.97  0.06   \n",
       "\n",
       "                                         sample_100_f1        \\\n",
       "                                                  mean   std   \n",
       "learner                sampling strategy                       \n",
       "LogisticRegression     entropy_sampling           0.88  0.20   \n",
       "                       random_sampling            0.75  0.31   \n",
       "RandomForestClassifier entropy_sampling           0.99  0.03   \n",
       "                       random_sampling            0.90  0.16   \n",
       "\n",
       "                                         sample_100_precision        \\\n",
       "                                                         mean   std   \n",
       "learner                sampling strategy                              \n",
       "LogisticRegression     entropy_sampling                  0.87  0.25   \n",
       "                       random_sampling                   0.75  0.33   \n",
       "RandomForestClassifier entropy_sampling                  1.00  0.00   \n",
       "                       random_sampling                   1.00  0.01   \n",
       "\n",
       "                                         sample_100_recall        \\\n",
       "                                                      mean   std   \n",
       "learner                sampling strategy                           \n",
       "LogisticRegression     entropy_sampling               0.91  0.13   \n",
       "                       random_sampling                0.75  0.30   \n",
       "RandomForestClassifier entropy_sampling               0.97  0.05   \n",
       "                       random_sampling                0.84  0.22   \n",
       "\n",
       "                                         sample_100_roc auc        \\\n",
       "                                                       mean   std   \n",
       "learner                sampling strategy                            \n",
       "LogisticRegression     entropy_sampling                0.99  0.02   \n",
       "                       random_sampling                 0.98  0.03   \n",
       "RandomForestClassifier entropy_sampling                0.99  0.03   \n",
       "                       random_sampling                 0.98  0.03   \n",
       "\n",
       "                                         sample_10_FN        sample_10_FP  \\\n",
       "                                                 mean    std         mean   \n",
       "learner                sampling strategy                                    \n",
       "LogisticRegression     entropy_sampling          14.5  27.91          6.6   \n",
       "                       random_sampling           19.1  27.73          9.2   \n",
       "RandomForestClassifier entropy_sampling           2.1   2.42          0.1   \n",
       "                       random_sampling            8.2   6.23          0.2   \n",
       "\n",
       "                                               sample_10_average precision  \\\n",
       "                                           std                        mean   \n",
       "learner                sampling strategy                                     \n",
       "LogisticRegression     entropy_sampling   7.20                        0.81   \n",
       "                       random_sampling    8.46                        0.73   \n",
       "RandomForestClassifier entropy_sampling   0.32                        0.97   \n",
       "                       random_sampling    0.63                        0.97   \n",
       "\n",
       "                                               sample_10_f1        \\\n",
       "                                           std         mean   std   \n",
       "learner                sampling strategy                            \n",
       "LogisticRegression     entropy_sampling   0.24         0.83  0.26   \n",
       "                       random_sampling    0.32         0.77  0.29   \n",
       "RandomForestClassifier entropy_sampling   0.05         0.98  0.03   \n",
       "                       random_sampling    0.05         0.94  0.07   \n",
       "\n",
       "                                         sample_10_precision        \\\n",
       "                                                        mean   std   \n",
       "learner                sampling strategy                             \n",
       "LogisticRegression     entropy_sampling                 0.93  0.10   \n",
       "                       random_sampling                  0.86  0.21   \n",
       "RandomForestClassifier entropy_sampling                 1.00  0.00   \n",
       "                       random_sampling                  1.00  0.01   \n",
       "\n",
       "                                         sample_10_recall        \\\n",
       "                                                     mean   std   \n",
       "learner                sampling strategy                          \n",
       "LogisticRegression     entropy_sampling              0.81  0.29   \n",
       "                       random_sampling               0.77  0.30   \n",
       "RandomForestClassifier entropy_sampling              0.97  0.05   \n",
       "                       random_sampling               0.90  0.12   \n",
       "\n",
       "                                         sample_10_roc auc       sample_1_FN  \\\n",
       "                                                      mean   std        mean   \n",
       "learner                sampling strategy                                       \n",
       "LogisticRegression     entropy_sampling               0.98  0.03        18.5   \n",
       "                       random_sampling                0.98  0.03        20.0   \n",
       "RandomForestClassifier entropy_sampling               0.99  0.03         6.8   \n",
       "                       random_sampling                0.99  0.03         8.0   \n",
       "\n",
       "                                                sample_1_FP         \\\n",
       "                                            std        mean    std   \n",
       "learner                sampling strategy                             \n",
       "LogisticRegression     entropy_sampling   27.85         7.7   8.53   \n",
       "                       random_sampling    29.82        14.8  19.86   \n",
       "RandomForestClassifier entropy_sampling    5.20         0.2   0.63   \n",
       "                       random_sampling     6.18         0.2   0.63   \n",
       "\n",
       "                                         sample_1_average precision        \\\n",
       "                                                               mean   std   \n",
       "learner                sampling strategy                                    \n",
       "LogisticRegression     entropy_sampling                        0.77  0.27   \n",
       "                       random_sampling                         0.71  0.35   \n",
       "RandomForestClassifier entropy_sampling                        0.97  0.05   \n",
       "                       random_sampling                         0.97  0.05   \n",
       "\n",
       "                                         sample_1_f1       sample_1_precision  \\\n",
       "                                                mean   std               mean   \n",
       "learner                sampling strategy                                        \n",
       "LogisticRegression     entropy_sampling         0.78  0.29               0.89   \n",
       "                       random_sampling          0.76  0.32               0.76   \n",
       "RandomForestClassifier entropy_sampling         0.96  0.05               1.00   \n",
       "                       random_sampling          0.94  0.07               1.00   \n",
       "\n",
       "                                               sample_1_recall        \\\n",
       "                                           std            mean   std   \n",
       "learner                sampling strategy                               \n",
       "LogisticRegression     entropy_sampling   0.17            0.78  0.30   \n",
       "                       random_sampling    0.34            0.77  0.31   \n",
       "RandomForestClassifier entropy_sampling   0.01            0.92  0.09   \n",
       "                       random_sampling    0.01            0.90  0.12   \n",
       "\n",
       "                                         sample_1_roc auc       sample_25_FN  \\\n",
       "                                                     mean   std         mean   \n",
       "learner                sampling strategy                                       \n",
       "LogisticRegression     entropy_sampling              0.98  0.03         13.1   \n",
       "                       random_sampling               0.97  0.04         19.0   \n",
       "RandomForestClassifier entropy_sampling              0.99  0.03          1.8   \n",
       "                       random_sampling               0.99  0.03         11.3   \n",
       "\n",
       "                                                sample_25_FP        \\\n",
       "                                            std         mean   std   \n",
       "learner                sampling strategy                             \n",
       "LogisticRegression     entropy_sampling   28.44          3.7  5.93   \n",
       "                       random_sampling    26.36          9.0  6.62   \n",
       "RandomForestClassifier entropy_sampling    2.25          0.3  0.67   \n",
       "                       random_sampling     8.33          0.5  1.08   \n",
       "\n",
       "                                         sample_25_average precision        \\\n",
       "                                                                mean   std   \n",
       "learner                sampling strategy                                     \n",
       "LogisticRegression     entropy_sampling                         0.85  0.20   \n",
       "                       random_sampling                          0.75  0.29   \n",
       "RandomForestClassifier entropy_sampling                         0.97  0.06   \n",
       "                       random_sampling                          0.96  0.06   \n",
       "\n",
       "                                         sample_25_f1        \\\n",
       "                                                 mean   std   \n",
       "learner                sampling strategy                      \n",
       "LogisticRegression     entropy_sampling          0.86  0.25   \n",
       "                       random_sampling           0.78  0.28   \n",
       "RandomForestClassifier entropy_sampling          0.98  0.04   \n",
       "                       random_sampling           0.88  0.16   \n",
       "\n",
       "                                         sample_25_precision        \\\n",
       "                                                        mean   std   \n",
       "learner                sampling strategy                             \n",
       "LogisticRegression     entropy_sampling                 0.96  0.06   \n",
       "                       random_sampling                  0.84  0.21   \n",
       "RandomForestClassifier entropy_sampling                 0.99  0.02   \n",
       "                       random_sampling                  0.99  0.01   \n",
       "\n",
       "                                         sample_25_recall        \\\n",
       "                                                     mean   std   \n",
       "learner                sampling strategy                          \n",
       "LogisticRegression     entropy_sampling              0.84  0.28   \n",
       "                       random_sampling               0.78  0.29   \n",
       "RandomForestClassifier entropy_sampling              0.97  0.05   \n",
       "                       random_sampling               0.82  0.22   \n",
       "\n",
       "                                         sample_25_roc auc       sample_50_FN  \\\n",
       "                                                      mean   std         mean   \n",
       "learner                sampling strategy                                        \n",
       "LogisticRegression     entropy_sampling               0.98  0.03         13.9   \n",
       "                       random_sampling                0.98  0.03         19.7   \n",
       "RandomForestClassifier entropy_sampling               0.99  0.03          1.4   \n",
       "                       random_sampling                0.98  0.03         10.2   \n",
       "\n",
       "                                                sample_50_FP        \\\n",
       "                                            std         mean   std   \n",
       "learner                sampling strategy                             \n",
       "LogisticRegression     entropy_sampling   32.00          2.8  5.81   \n",
       "                       random_sampling    29.89          9.1  7.67   \n",
       "RandomForestClassifier entropy_sampling    1.71          0.1  0.32   \n",
       "                       random_sampling     8.05          0.1  0.32   \n",
       "\n",
       "                                         sample_50_average precision        \\\n",
       "                                                                mean   std   \n",
       "learner                sampling strategy                                     \n",
       "LogisticRegression     entropy_sampling                         0.82  0.29   \n",
       "                       random_sampling                          0.74  0.30   \n",
       "RandomForestClassifier entropy_sampling                         0.98  0.05   \n",
       "                       random_sampling                          0.96  0.06   \n",
       "\n",
       "                                         sample_50_f1        \\\n",
       "                                                 mean   std   \n",
       "learner                sampling strategy                      \n",
       "LogisticRegression     entropy_sampling          0.85  0.31   \n",
       "                       random_sampling           0.76  0.32   \n",
       "RandomForestClassifier entropy_sampling          0.98  0.03   \n",
       "                       random_sampling           0.89  0.16   \n",
       "\n",
       "                                         sample_50_precision        \\\n",
       "                                                        mean   std   \n",
       "learner                sampling strategy                             \n",
       "LogisticRegression     entropy_sampling                 0.88  0.31   \n",
       "                       random_sampling                  0.75  0.33   \n",
       "RandomForestClassifier entropy_sampling                 1.00  0.00   \n",
       "                       random_sampling                  1.00  0.00   \n",
       "\n",
       "                                         sample_50_recall        \\\n",
       "                                                     mean   std   \n",
       "learner                sampling strategy                          \n",
       "LogisticRegression     entropy_sampling              0.83  0.31   \n",
       "                       random_sampling               0.77  0.31   \n",
       "RandomForestClassifier entropy_sampling              0.97  0.05   \n",
       "                       random_sampling               0.84  0.23   \n",
       "\n",
       "                                         sample_50_roc auc        \\\n",
       "                                                      mean   std   \n",
       "learner                sampling strategy                           \n",
       "LogisticRegression     entropy_sampling               0.98  0.03   \n",
       "                       random_sampling                0.98  0.03   \n",
       "RandomForestClassifier entropy_sampling               0.99  0.03   \n",
       "                       random_sampling                0.98  0.03   \n",
       "\n",
       "                                         train time (s)        \n",
       "                                                   mean   std  \n",
       "learner                sampling strategy                       \n",
       "LogisticRegression     entropy_sampling            0.03  0.00  \n",
       "                       random_sampling             0.03  0.01  \n",
       "RandomForestClassifier entropy_sampling            0.11  0.00  \n",
       "                       random_sampling             0.11  0.00  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ni.report_active_learning_across_labels()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('RandomForestClassifier', 'random_sampling'): {'0.04±0.04'},\n",
       " ('RandomForestClassifier', 'entropy_sampling'): {'0.18±0.07'},\n",
       " ('LogisticRegression', 'random_sampling'): {'0.04±0.04'},\n",
       " ('LogisticRegression', 'entropy_sampling'): {'0.04±0.04'}}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ni.report_active_learning_query_time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ni.plot_active_learning_time_series_overlapping(\n",
    "    attribute='f1', label='smurf',\n",
    "    learner1='RandomForestClassifier', sampling1='entropy',\n",
    "    learner2='RandomForestClassifier', sampling2='random',\n",
    "    title='Random forest for smurf attack',\n",
    "    ylim=[0.9980, 1.0001], ylabel='F1',\n",
    "    legend=['Entropy sampling', 'Random sampling']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ni.plot_active_learning_time_series_overlapping(\n",
    "    attribute='f1', label='smurf',\n",
    "    learner1='LogisticRegression', sampling1='entropy',\n",
    "    learner2='LogisticRegression', sampling2='random',\n",
    "    title='Logistic regression for smurf attack',\n",
    "    ylim=[0.9980, 1.0001], ylabel='F1',\n",
    "    legend=['Entropy sampling', 'Random sampling']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ni.plot_active_learning_time_series_overlapping(\n",
    "    attribute='f1', label='nmap',\n",
    "    learner1='RandomForestClassifier', sampling1='entropy',\n",
    "    learner2='RandomForestClassifier', sampling2='random',\n",
    "    title='Random forest for nmap attack',\n",
    "    ylim=[0, 1], ylabel='F1',\n",
    "    legend=['Entropy sampling', 'Random sampling']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ni.plot_active_learning_time_series_overlapping(\n",
    "    attribute='f1', label='nmap',\n",
    "    learner1='LogisticRegression', sampling1='entropy',\n",
    "    learner2='LogisticRegression', sampling2='random',\n",
    "    title='Logistic regression for nmap attack',\n",
    "    ylim=[0, 1], ylabel='F1',\n",
    "    legend=['Entropy sampling', 'Random sampling']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: smurf., learner: VotingClassifier, sampling strategy: entropy_sampling\n",
      "Already exists in cache, returning...\n",
      "Label: neptune., learner: VotingClassifier, sampling strategy: entropy_sampling\n",
      "Already exists in cache, returning...\n",
      "Label: back., learner: VotingClassifier, sampling strategy: entropy_sampling\n",
      "Already exists in cache, returning...\n",
      "Label: satan., learner: VotingClassifier, sampling strategy: entropy_sampling\n",
      "Already exists in cache, returning...\n",
      "Label: ipsweep., learner: VotingClassifier, sampling strategy: entropy_sampling\n",
      "Already exists in cache, returning...\n",
      "Label: portsweep., learner: VotingClassifier, sampling strategy: entropy_sampling\n",
      "Already exists in cache, returning...\n",
      "Label: warezclient., learner: VotingClassifier, sampling strategy: entropy_sampling\n",
      "Already exists in cache, returning...\n",
      "Label: teardrop., learner: VotingClassifier, sampling strategy: entropy_sampling\n",
      "Already exists in cache, returning...\n",
      "Label: pod., learner: VotingClassifier, sampling strategy: entropy_sampling\n",
      "Already exists in cache, returning...\n",
      "Label: nmap., learner: VotingClassifier, sampling strategy: entropy_sampling\n",
      "Already exists in cache, returning...\n"
     ]
    }
   ],
   "source": [
    "df_ensemble = ni.report_ensemble()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>initial_FN</th>\n",
       "      <th>initial_FP</th>\n",
       "      <th>initial_f1</th>\n",
       "      <th>initial_precision</th>\n",
       "      <th>initial_recall</th>\n",
       "      <th>label</th>\n",
       "      <th>learner</th>\n",
       "      <th>sample_100_FN</th>\n",
       "      <th>sample_100_FP</th>\n",
       "      <th>sample_100_f1</th>\n",
       "      <th>sample_100_precision</th>\n",
       "      <th>sample_100_recall</th>\n",
       "      <th>sample_10_FN</th>\n",
       "      <th>sample_10_FP</th>\n",
       "      <th>sample_10_f1</th>\n",
       "      <th>sample_10_precision</th>\n",
       "      <th>sample_10_recall</th>\n",
       "      <th>sample_1_FN</th>\n",
       "      <th>sample_1_FP</th>\n",
       "      <th>sample_1_f1</th>\n",
       "      <th>sample_1_precision</th>\n",
       "      <th>sample_1_recall</th>\n",
       "      <th>sample_25_FN</th>\n",
       "      <th>sample_25_FP</th>\n",
       "      <th>sample_25_f1</th>\n",
       "      <th>sample_25_precision</th>\n",
       "      <th>sample_25_recall</th>\n",
       "      <th>sample_50_FN</th>\n",
       "      <th>sample_50_FP</th>\n",
       "      <th>sample_50_f1</th>\n",
       "      <th>sample_50_precision</th>\n",
       "      <th>sample_50_recall</th>\n",
       "      <th>sampling strategy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8867</td>\n",
       "      <td>0</td>\n",
       "      <td>0.812501</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.684212</td>\n",
       "      <td>smurf.</td>\n",
       "      <td>VotingClassifier</td>\n",
       "      <td>8867</td>\n",
       "      <td>0</td>\n",
       "      <td>0.812501</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.684212</td>\n",
       "      <td>8867</td>\n",
       "      <td>0</td>\n",
       "      <td>0.812501</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.684212</td>\n",
       "      <td>8867</td>\n",
       "      <td>0</td>\n",
       "      <td>0.812501</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.684212</td>\n",
       "      <td>8867</td>\n",
       "      <td>0</td>\n",
       "      <td>0.812501</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.684212</td>\n",
       "      <td>8867</td>\n",
       "      <td>0</td>\n",
       "      <td>0.812501</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.684212</td>\n",
       "      <td>entropy_sampling</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4487</td>\n",
       "      <td>0</td>\n",
       "      <td>0.735327</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.581437</td>\n",
       "      <td>neptune.</td>\n",
       "      <td>VotingClassifier</td>\n",
       "      <td>4487</td>\n",
       "      <td>0</td>\n",
       "      <td>0.735327</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.581437</td>\n",
       "      <td>4487</td>\n",
       "      <td>0</td>\n",
       "      <td>0.735327</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.581437</td>\n",
       "      <td>4487</td>\n",
       "      <td>0</td>\n",
       "      <td>0.735327</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.581437</td>\n",
       "      <td>4487</td>\n",
       "      <td>0</td>\n",
       "      <td>0.735327</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.581437</td>\n",
       "      <td>4487</td>\n",
       "      <td>0</td>\n",
       "      <td>0.735327</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.581437</td>\n",
       "      <td>entropy_sampling</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0.976744</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.954545</td>\n",
       "      <td>back.</td>\n",
       "      <td>VotingClassifier</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0.976744</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.954545</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0.976744</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.954545</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0.974359</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0.976744</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.954545</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0.974359</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>entropy_sampling</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>159</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>satan.</td>\n",
       "      <td>VotingClassifier</td>\n",
       "      <td>143</td>\n",
       "      <td>0</td>\n",
       "      <td>0.182857</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.100629</td>\n",
       "      <td>148</td>\n",
       "      <td>0</td>\n",
       "      <td>0.129412</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.069182</td>\n",
       "      <td>159</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>143</td>\n",
       "      <td>0</td>\n",
       "      <td>0.182857</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.100629</td>\n",
       "      <td>143</td>\n",
       "      <td>0</td>\n",
       "      <td>0.182857</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.100629</td>\n",
       "      <td>entropy_sampling</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.983740</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.968000</td>\n",
       "      <td>ipsweep.</td>\n",
       "      <td>VotingClassifier</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.995984</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.992000</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.983740</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.968000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.995984</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.992000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.995984</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.992000</td>\n",
       "      <td>entropy_sampling</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>0.776471</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.634615</td>\n",
       "      <td>portsweep.</td>\n",
       "      <td>VotingClassifier</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>0.776471</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.634615</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>0.776471</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.634615</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>0.776471</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.634615</td>\n",
       "      <td>entropy_sampling</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>0.869565</td>\n",
       "      <td>0.97561</td>\n",
       "      <td>0.784314</td>\n",
       "      <td>warezclient.</td>\n",
       "      <td>VotingClassifier</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0.953846</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.911765</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0.943590</td>\n",
       "      <td>0.989247</td>\n",
       "      <td>0.901961</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>0.893617</td>\n",
       "      <td>0.976744</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>0.938776</td>\n",
       "      <td>0.978723</td>\n",
       "      <td>0.901961</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0.948980</td>\n",
       "      <td>0.989362</td>\n",
       "      <td>0.911765</td>\n",
       "      <td>entropy_sampling</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>0.873563</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.775510</td>\n",
       "      <td>teardrop.</td>\n",
       "      <td>VotingClassifier</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0.917127</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.846939</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0.917127</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.846939</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>0.892655</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.806122</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.898876</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.816327</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0.917127</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.846939</td>\n",
       "      <td>entropy_sampling</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0.844444</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.730769</td>\n",
       "      <td>pod.</td>\n",
       "      <td>VotingClassifier</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.938776</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.884615</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.938776</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.884615</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0.869565</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.938776</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.884615</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.938776</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.884615</td>\n",
       "      <td>entropy_sampling</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0.820513</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.695652</td>\n",
       "      <td>nmap.</td>\n",
       "      <td>VotingClassifier</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.826087</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.826087</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.739130</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.883721</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>0.826087</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.826087</td>\n",
       "      <td>entropy_sampling</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   initial_FN  initial_FP  initial_f1  initial_precision  initial_recall  \\\n",
       "0        8867           0    0.812501            1.00000        0.684212   \n",
       "0        4487           0    0.735327            1.00000        0.581437   \n",
       "0          10           0    0.976744            1.00000        0.954545   \n",
       "0         159           0    0.000000            0.00000        0.000000   \n",
       "0           4           0    0.983740            1.00000        0.968000   \n",
       "0          38           0    0.776471            1.00000        0.634615   \n",
       "0          22           2    0.869565            0.97561        0.784314   \n",
       "0          22           0    0.873563            1.00000        0.775510   \n",
       "0           7           0    0.844444            1.00000        0.730769   \n",
       "0           7           0    0.820513            1.00000        0.695652   \n",
       "\n",
       "          label           learner  sample_100_FN  sample_100_FP  \\\n",
       "0        smurf.  VotingClassifier           8867              0   \n",
       "0      neptune.  VotingClassifier           4487              0   \n",
       "0         back.  VotingClassifier             10              0   \n",
       "0        satan.  VotingClassifier            143              0   \n",
       "0      ipsweep.  VotingClassifier              0              0   \n",
       "0    portsweep.  VotingClassifier             38              0   \n",
       "0  warezclient.  VotingClassifier              9              0   \n",
       "0     teardrop.  VotingClassifier             15              0   \n",
       "0          pod.  VotingClassifier              3              0   \n",
       "0         nmap.  VotingClassifier              4              0   \n",
       "\n",
       "   sample_100_f1  sample_100_precision  sample_100_recall  sample_10_FN  \\\n",
       "0       0.812501                   1.0           0.684212          8867   \n",
       "0       0.735327                   1.0           0.581437          4487   \n",
       "0       0.976744                   1.0           0.954545            10   \n",
       "0       0.182857                   1.0           0.100629           148   \n",
       "0       1.000000                   1.0           1.000000             1   \n",
       "0       0.776471                   1.0           0.634615            39   \n",
       "0       0.953846                   1.0           0.911765            10   \n",
       "0       0.917127                   1.0           0.846939            15   \n",
       "0       0.938776                   1.0           0.884615             3   \n",
       "0       0.904762                   1.0           0.826087             4   \n",
       "\n",
       "   sample_10_FP  sample_10_f1  sample_10_precision  sample_10_recall  \\\n",
       "0             0      0.812501             1.000000          0.684212   \n",
       "0             0      0.735327             1.000000          0.581437   \n",
       "0             0      0.976744             1.000000          0.954545   \n",
       "0             0      0.129412             1.000000          0.069182   \n",
       "0             0      0.995984             1.000000          0.992000   \n",
       "0             0      0.769231             1.000000          0.625000   \n",
       "0             1      0.943590             0.989247          0.901961   \n",
       "0             0      0.917127             1.000000          0.846939   \n",
       "0             0      0.938776             1.000000          0.884615   \n",
       "0             0      0.904762             1.000000          0.826087   \n",
       "\n",
       "   sample_1_FN  sample_1_FP  sample_1_f1  sample_1_precision  sample_1_recall  \\\n",
       "0         8867            0     0.812501            1.000000         0.684212   \n",
       "0         4487            0     0.735327            1.000000         0.581437   \n",
       "0           11            0     0.974359            1.000000         0.950000   \n",
       "0          159            0     0.000000            0.000000         0.000000   \n",
       "0            4            0     0.983740            1.000000         0.968000   \n",
       "0           39            0     0.769231            1.000000         0.625000   \n",
       "0           18            2     0.893617            0.976744         0.823529   \n",
       "0           19            0     0.892655            1.000000         0.806122   \n",
       "0            6            0     0.869565            1.000000         0.769231   \n",
       "0            6            0     0.850000            1.000000         0.739130   \n",
       "\n",
       "   sample_25_FN  sample_25_FP  sample_25_f1  sample_25_precision  \\\n",
       "0          8867             0      0.812501             1.000000   \n",
       "0          4487             0      0.735327             1.000000   \n",
       "0            10             0      0.976744             1.000000   \n",
       "0           143             0      0.182857             1.000000   \n",
       "0             1             0      0.995984             1.000000   \n",
       "0            38             0      0.776471             1.000000   \n",
       "0            10             2      0.938776             0.978723   \n",
       "0            18             0      0.898876             1.000000   \n",
       "0             3             0      0.938776             1.000000   \n",
       "0             4             1      0.883721             0.950000   \n",
       "\n",
       "   sample_25_recall  sample_50_FN  sample_50_FP  sample_50_f1  \\\n",
       "0          0.684212          8867             0      0.812501   \n",
       "0          0.581437          4487             0      0.735327   \n",
       "0          0.954545            11             0      0.974359   \n",
       "0          0.100629           143             0      0.182857   \n",
       "0          0.992000             1             0      0.995984   \n",
       "0          0.634615            38             0      0.776471   \n",
       "0          0.901961             9             1      0.948980   \n",
       "0          0.816327            15             0      0.917127   \n",
       "0          0.884615             3             0      0.938776   \n",
       "0          0.826087             4             0      0.904762   \n",
       "\n",
       "   sample_50_precision  sample_50_recall sampling strategy  \n",
       "0             1.000000          0.684212  entropy_sampling  \n",
       "0             1.000000          0.581437  entropy_sampling  \n",
       "0             1.000000          0.950000  entropy_sampling  \n",
       "0             1.000000          0.100629  entropy_sampling  \n",
       "0             1.000000          0.992000  entropy_sampling  \n",
       "0             1.000000          0.634615  entropy_sampling  \n",
       "0             0.989362          0.911765  entropy_sampling  \n",
       "0             1.000000          0.846939  entropy_sampling  \n",
       "0             1.000000          0.884615  entropy_sampling  \n",
       "0             1.000000          0.826087  entropy_sampling  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">initial_FN</th>\n",
       "      <th colspan=\"2\" halign=\"left\">initial_FP</th>\n",
       "      <th colspan=\"2\" halign=\"left\">initial_f1</th>\n",
       "      <th colspan=\"2\" halign=\"left\">initial_precision</th>\n",
       "      <th colspan=\"2\" halign=\"left\">initial_recall</th>\n",
       "      <th colspan=\"2\" halign=\"left\">sample_100_FN</th>\n",
       "      <th colspan=\"2\" halign=\"left\">sample_100_FP</th>\n",
       "      <th colspan=\"2\" halign=\"left\">sample_100_f1</th>\n",
       "      <th colspan=\"2\" halign=\"left\">sample_100_precision</th>\n",
       "      <th colspan=\"2\" halign=\"left\">sample_100_recall</th>\n",
       "      <th colspan=\"2\" halign=\"left\">sample_10_FN</th>\n",
       "      <th colspan=\"2\" halign=\"left\">sample_10_FP</th>\n",
       "      <th colspan=\"2\" halign=\"left\">sample_10_f1</th>\n",
       "      <th colspan=\"2\" halign=\"left\">sample_10_precision</th>\n",
       "      <th colspan=\"2\" halign=\"left\">sample_10_recall</th>\n",
       "      <th colspan=\"2\" halign=\"left\">sample_1_FN</th>\n",
       "      <th colspan=\"2\" halign=\"left\">sample_1_FP</th>\n",
       "      <th colspan=\"2\" halign=\"left\">sample_1_f1</th>\n",
       "      <th colspan=\"2\" halign=\"left\">sample_1_precision</th>\n",
       "      <th colspan=\"2\" halign=\"left\">sample_1_recall</th>\n",
       "      <th colspan=\"2\" halign=\"left\">sample_25_FN</th>\n",
       "      <th colspan=\"2\" halign=\"left\">sample_25_FP</th>\n",
       "      <th colspan=\"2\" halign=\"left\">sample_25_f1</th>\n",
       "      <th colspan=\"2\" halign=\"left\">sample_25_precision</th>\n",
       "      <th colspan=\"2\" halign=\"left\">sample_25_recall</th>\n",
       "      <th colspan=\"2\" halign=\"left\">sample_50_FN</th>\n",
       "      <th colspan=\"2\" halign=\"left\">sample_50_FP</th>\n",
       "      <th colspan=\"2\" halign=\"left\">sample_50_f1</th>\n",
       "      <th colspan=\"2\" halign=\"left\">sample_50_precision</th>\n",
       "      <th colspan=\"2\" halign=\"left\">sample_50_recall</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>learner</th>\n",
       "      <th>sampling strategy</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>VotingClassifier</th>\n",
       "      <th>entropy_sampling</th>\n",
       "      <td>1362.3</td>\n",
       "      <td>2985.64</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.27</td>\n",
       "      <td>1357.6</td>\n",
       "      <td>2987.91</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.24</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1358.4</td>\n",
       "      <td>2987.53</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.27</td>\n",
       "      <td>1361.6</td>\n",
       "      <td>2985.99</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.27</td>\n",
       "      <td>1358.1</td>\n",
       "      <td>2987.66</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1357.8</td>\n",
       "      <td>2987.81</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.24</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   initial_FN          initial_FP        \\\n",
       "                                         mean      std       mean   std   \n",
       "learner          sampling strategy                                        \n",
       "VotingClassifier entropy_sampling      1362.3  2985.64        0.2  0.63   \n",
       "\n",
       "                                   initial_f1       initial_precision        \\\n",
       "                                         mean   std              mean   std   \n",
       "learner          sampling strategy                                            \n",
       "VotingClassifier entropy_sampling        0.77  0.28               0.9  0.32   \n",
       "\n",
       "                                   initial_recall       sample_100_FN  \\\n",
       "                                             mean   std          mean   \n",
       "learner          sampling strategy                                      \n",
       "VotingClassifier entropy_sampling            0.68  0.27        1357.6   \n",
       "\n",
       "                                            sample_100_FP      sample_100_f1  \\\n",
       "                                        std          mean  std          mean   \n",
       "learner          sampling strategy                                             \n",
       "VotingClassifier entropy_sampling   2987.91             0  0.0          0.82   \n",
       "\n",
       "                                         sample_100_precision       \\\n",
       "                                     std                 mean  std   \n",
       "learner          sampling strategy                                   \n",
       "VotingClassifier entropy_sampling   0.24                  1.0  0.0   \n",
       "\n",
       "                                   sample_100_recall       sample_10_FN  \\\n",
       "                                                mean   std         mean   \n",
       "learner          sampling strategy                                        \n",
       "VotingClassifier entropy_sampling               0.74  0.26       1358.4   \n",
       "\n",
       "                                            sample_10_FP       sample_10_f1  \\\n",
       "                                        std         mean   std         mean   \n",
       "learner          sampling strategy                                            \n",
       "VotingClassifier entropy_sampling   2987.53          0.1  0.32         0.81   \n",
       "\n",
       "                                         sample_10_precision       \\\n",
       "                                     std                mean  std   \n",
       "learner          sampling strategy                                  \n",
       "VotingClassifier entropy_sampling   0.26                 1.0  0.0   \n",
       "\n",
       "                                   sample_10_recall       sample_1_FN  \\\n",
       "                                               mean   std        mean   \n",
       "learner          sampling strategy                                      \n",
       "VotingClassifier entropy_sampling              0.74  0.27      1361.6   \n",
       "\n",
       "                                            sample_1_FP       sample_1_f1  \\\n",
       "                                        std        mean   std        mean   \n",
       "learner          sampling strategy                                          \n",
       "VotingClassifier entropy_sampling   2985.99         0.2  0.63        0.78   \n",
       "\n",
       "                                         sample_1_precision        \\\n",
       "                                     std               mean   std   \n",
       "learner          sampling strategy                                  \n",
       "VotingClassifier entropy_sampling   0.28                0.9  0.32   \n",
       "\n",
       "                                   sample_1_recall       sample_25_FN  \\\n",
       "                                              mean   std         mean   \n",
       "learner          sampling strategy                                      \n",
       "VotingClassifier entropy_sampling             0.69  0.27       1358.1   \n",
       "\n",
       "                                            sample_25_FP       sample_25_f1  \\\n",
       "                                        std         mean   std         mean   \n",
       "learner          sampling strategy                                            \n",
       "VotingClassifier entropy_sampling   2987.66          0.3  0.67         0.81   \n",
       "\n",
       "                                         sample_25_precision        \\\n",
       "                                     std                mean   std   \n",
       "learner          sampling strategy                                   \n",
       "VotingClassifier entropy_sampling   0.24                0.99  0.02   \n",
       "\n",
       "                                   sample_25_recall       sample_50_FN  \\\n",
       "                                               mean   std         mean   \n",
       "learner          sampling strategy                                       \n",
       "VotingClassifier entropy_sampling              0.74  0.26       1357.8   \n",
       "\n",
       "                                            sample_50_FP       sample_50_f1  \\\n",
       "                                        std         mean   std         mean   \n",
       "learner          sampling strategy                                            \n",
       "VotingClassifier entropy_sampling   2987.81          0.1  0.32         0.82   \n",
       "\n",
       "                                         sample_50_precision       \\\n",
       "                                     std                mean  std   \n",
       "learner          sampling strategy                                  \n",
       "VotingClassifier entropy_sampling   0.24                 1.0  0.0   \n",
       "\n",
       "                                   sample_50_recall        \n",
       "                                               mean   std  \n",
       "learner          sampling strategy                         \n",
       "VotingClassifier entropy_sampling              0.74  0.26  "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ensemble.groupby(['learner', 'sampling strategy']).agg([np.mean, np.std]).round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ni.plot_active_learning_time_series_overlapping(\n",
    "    attribute='f1', label='smurf',\n",
    "    learner1='RandomForestClassifier', sampling1='entropy',\n",
    "    learner2='VotingClassifier', sampling2='entropy',\n",
    "    title='Random forest for nmap attack',\n",
    "    ylim=[0, 1], ylabel='F1',\n",
    "    legend=['Random Forest', 'Ensemble']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, IsolationForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/forest.py:248: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=None,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(ni.splits['smurf.']['x_train'], ni.splits['smurf.']['y_train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True, ...,  True,  True, False])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict(ni.splits['smurf.']['x_dev'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "fit() got an unexpected keyword argument 'contamination'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-104-d647c80fa03c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0miforest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mIsolationForest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0miforest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mni\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplits\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'smurf.'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'x_train'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontamination\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: fit() got an unexpected keyword argument 'contamination'"
     ]
    }
   ],
   "source": [
    "iforest = IsolationForest(contamination=0.1)\n",
    "iforest.fit(ni.splits['smurf.']['x_train'], )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
